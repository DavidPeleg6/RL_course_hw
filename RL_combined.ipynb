{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d7de38-6971-47bd-b701-31d95b165fb8",
   "metadata": {},
   "source": [
    "# Cart Pole"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1dfee0c",
   "metadata": {},
   "source": [
    "## Class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7761b5-9908-42b8-9b5d-3f51c93cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from math import sin, cos, pi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "class CartPole:\n",
    "    def __init__(self, physics):\n",
    "        self.physics = physics\n",
    "        self.mass_cart = 1.0\n",
    "        self.mass_pole = 0.3\n",
    "        self.mass = self.mass_cart + self.mass_pole\n",
    "        self.length = 0.7 # actually half the pole length\n",
    "        self.pole_mass_length = self.mass_pole * self.length\n",
    "\n",
    "    def simulate(self, action, state_tuple):\n",
    "        \"\"\"\n",
    "        Simulation dynamics of the cart-pole system\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int\n",
    "            Action represented as 0 or 1\n",
    "        state_tuple : tuple\n",
    "            Continuous vector of x, x_dot, theta, theta_dot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        new_state : tuple\n",
    "            Updated state vector of new_x, new_x_dot, nwe_theta, new_theta_dot\n",
    "        \"\"\"\n",
    "        x, x_dot, theta, theta_dot = state_tuple\n",
    "        costheta, sintheta = cos(theta), sin(theta)\n",
    "        # costheta, sintheta = cos(theta * 180 / pi), sin(theta * 180 / pi)\n",
    "\n",
    "        # calculate force based on action\n",
    "        force = self.physics.force_mag if action > 0 else (-1 * self.physics.force_mag)\n",
    "\n",
    "        # intermediate calculation\n",
    "        temp = (force + self.pole_mass_length * theta_dot * theta_dot * sintheta) / self.mass\n",
    "        theta_acc = (self.physics.gravity * sintheta - temp * costheta) / (self.length * (4/3 - self.mass_pole * costheta * costheta / self.mass))\n",
    "\n",
    "        x_acc = temp - self.pole_mass_length * theta_acc * costheta / self.mass\n",
    "\n",
    "        # return new state variable using Euler's method\n",
    "        new_x = x + self.physics.tau * x_dot\n",
    "        new_x_dot = x_dot + self.physics.tau * x_acc\n",
    "        new_theta = theta + self.physics.tau * theta_dot\n",
    "        new_theta_dot = theta_dot + self.physics.tau * theta_acc\n",
    "        new_state = (new_x, new_x_dot, new_theta, new_theta_dot)\n",
    "\n",
    "        return new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe43be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(self, state_tuple):\n",
    "        \"\"\"\n",
    "        Discretizes the continuous state vector. The current discretization\n",
    "        divides x into 3, x_dot into 3, theta into 6 and theta_dot into 3\n",
    "        categories. A finer discretization produces a larger state space\n",
    "        but allows for a better policy\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_tuple : tuple\n",
    "            Continuous vector of x, x_dot, theta, theta_dot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        state : int\n",
    "            Discretized state value\n",
    "        \"\"\"\n",
    "        x, x_dot, theta, theta_dot = state_tuple\n",
    "        # parameters for state discretization in get_state\n",
    "        # convert degrees to radians\n",
    "        one_deg = pi / 180\n",
    "        six_deg = 6 * pi / 180\n",
    "        twelve_deg = 12 * pi / 180\n",
    "        fifty_deg = 50 * pi / 180\n",
    "\n",
    "        total_states = 163\n",
    "        state = 0\n",
    "\n",
    "        if x < -2.4 or x > 2.4 or theta < -twelve_deg or theta > twelve_deg:\n",
    "            state = total_states - 1 # to signal failure\n",
    "        else:\n",
    "            # x: 3 categories\n",
    "            if x < -1.5:\n",
    "                state = 0\n",
    "            elif x < 1.5:\n",
    "                state = 1\n",
    "            else:\n",
    "                state = 2\n",
    "            # x_dot: 3 categories\n",
    "            if x_dot < -0.5:\n",
    "                pass\n",
    "            elif x_dot < 0.5:\n",
    "                state += 3\n",
    "            else:\n",
    "                state += 6\n",
    "            # theta: 6 categories\n",
    "            if theta < -six_deg:\n",
    "                pass\n",
    "            elif theta < -one_deg:\n",
    "                state += 9\n",
    "            elif theta < 0:\n",
    "                state += 18\n",
    "            elif theta < one_deg:\n",
    "                state += 27\n",
    "            elif theta < six_deg:\n",
    "                state += 36\n",
    "            else:\n",
    "                state += 45\n",
    "            # theta_dot: 3 categories\n",
    "            if theta_dot < -fifty_deg:\n",
    "                pass\n",
    "            elif theta_dot < fifty_deg:\n",
    "                state += 54\n",
    "            else:\n",
    "                state += 108\n",
    "        # state += 1 # converting from MATLAB 1-indexing to 0-indexing\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76b8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cart(self, state_tuple, pause_time):\n",
    "        \"\"\"\n",
    "        Given the `state_tuple`, displays the cart-pole system.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_tuple : tuple\n",
    "            Continuous vector of x, x_dot, theta, theta_dot\n",
    "        pause_time : float\n",
    "            Time delay in seconds\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        x, x_dot, theta, theta_dot = state_tuple\n",
    "        X = [x, x + 4*self.length * sin(theta)]\n",
    "        Y = [0, 4*self.length * cos(theta)]\n",
    "        plt.close('all')\n",
    "        fig, ax = plt.subplots(1)\n",
    "        plt.ion()\n",
    "        ax.set_xlim(-3, 3)\n",
    "        ax.set_ylim(-0.5, 3.5)\n",
    "        ax.plot(X, Y)\n",
    "        cart = patches.Rectangle((x - 0.4, -0.25), 0.8, 0.25,\n",
    "                        linewidth=1, edgecolor='k', facecolor='cyan')\n",
    "        base = patches.Rectangle((x - 0.01, -0.5), 0.02, 0.25,\n",
    "                        linewidth=1, edgecolor='k', facecolor='r')\n",
    "        ax.add_patch(cart)\n",
    "        ax.add_patch(base)\n",
    "        x_dot_str, theta_str, theta_dot_str = '\\\\dot{x}', '\\\\theta', '\\\\dot{\\\\theta}'\n",
    "        ax.set_title('x: %.3f, $%s$: %.3f, $%s$: %.3f, $%s$: %.3f'\\\n",
    "                                %(x, x_dot_str, x_dot, theta_str, theta, theta_dot_str, x))\n",
    "        plt.show()\n",
    "        plt.pause(pause_time)\n",
    "\n",
    "class Physics:\n",
    "    gravity = 9.8\n",
    "    force_mag = 10.0\n",
    "    tau = 0.02 # seconds between state updates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e6444a",
   "metadata": {},
   "source": [
    "## Control Via Value Iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "547ee086",
   "metadata": {},
   "source": [
    "\n",
    "Parts of the code (cart and pole dynamics, and the state discretization) are inspired from code available at the RL repository http://www-anw.cs.umass.edu/rlr/domains.html\n",
    "\n",
    "This file controls the pole-balancing simulation. You only need to write code in between places marked\n",
    "###### BEGIN YOUR CODE ######\n",
    "###### END YOUR CODE ######\n",
    "\n",
    "Briefly, the cart-pole system is described in `cart_pole.py`. The main simulation loop in this file calls the `simulate()` function for simulating the pole dynamics, `get_state()` for discretizing the otherwise continuous state space in discrete states, and `show_cart()` for display.\n",
    "\n",
    "Some useful parameters are listed below:\n",
    "\n",
    "`NUM_STATES`: Number of states in the discretized state space You must assume that states are numbered 0 through `NUM_STATES` - 1. The state numbered `NUM_STATES` - 1 (the last one) is a special state that marks the state when the pole has been judged to have fallen (or when the cart is out of bounds). However, you should NOT treat this state any differently in your code. Any distinctions you need to make between states should come automatically from your learning algorithm.\n",
    "\n",
    "After each simulation cycle, you are supposed to update the transition counts and rewards observed. However, you should not change either your value function or the transition probability matrix at each cycle.\n",
    "\n",
    "Whenever the pole falls, a section of your code below will be executed. At this point, you must use the transition counts and reward observations that you have gathered to generate a new model for the MDP (i.e. transition probabilities and state rewards). After that, you must use value iteration to get the optimal value function for this MDP model.\n",
    "\n",
    "`TOLERANCE`: Controls the convergence criteria for each value iteration run. In value iteration, you can assume convergence when the maximum absolute change in the value function at any state in an iteration becomes lower than `TOLERANCE.\n",
    "\n",
    "You need to write code that chooses the best action according to your current value function, and the current model of the MDP. The action must be either 0 or 1 (corresponding to possible directions of pushing the cart)\n",
    "\n",
    "Finally, we assume that the simulation has converged when `NO_LEARNING_THRESHOLD` consecutive value function computations all converged within one value function iteration. Intuitively, it seems like there will be little learning after this, so we end the simulation here, and say the overall algorithm has converged.\n",
    "\n",
    "\n",
    "Learning curves can be generated by calling a code snippet at the end (it assumes that the learning was just executed, and the array `time_steps_to_failure` that records the time for which the pole was balanced before each failure are in memory). `num_failures` is a variable that stores the number of failures (pole drops / cart out of bounds) till now.\n",
    "\n",
    "Other parameters in the code are described below:\n",
    "\n",
    "`GAMMA`: Discount factor to be used\n",
    "\n",
    "The following parameters control the simulation display; you dont really need to know about them:\n",
    "\n",
    "`pause_time`: Controls the pause between successive frames of the display. Higher values make your simulation slower.\n",
    "`min_trial_length_to_start_display`: Allows you to start the display only after the pole has been successfully balanced for at least this many trials. Setting this to zero starts the display immediately. Choosing a reasonably high value (around 100) can allow you to rush through the initial learning quickly, and start the display only after the performance is reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0dda0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS 229 Machine Learning, Fall 2017\n",
    "Problem Set 4\n",
    "Question: Reinforcement Learning: The inverted pendulum\n",
    "Author: Sanyam Mehra, sanyam@stanford.edu\n",
    "\"\"\"\n",
    "from __future__ import division, print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "\n",
    "# Simulation parameters\n",
    "pause_time = 0.0001\n",
    "min_trial_length_to_start_display = 100\n",
    "display_started = min_trial_length_to_start_display == 0\n",
    "\n",
    "NUM_STATES = 163\n",
    "NUM_ACTIONS = 2\n",
    "GAMMA = 0.995\n",
    "TOLERANCE = 0.01\n",
    "NO_LEARNING_THRESHOLD = 20\n",
    "\n",
    "# Time cycle of the simulation\n",
    "time = 0\n",
    "\n",
    "# These variables perform bookkeeping (how many cycles was the pole\n",
    "# balanced for before it fell). Useful for plotting learning curves.\n",
    "time_steps_to_failure = []\n",
    "num_failures = 0\n",
    "time_at_start_of_current_trial = 0\n",
    "\n",
    "# You should reach convergence well before this\n",
    "max_failures = 500\n",
    "\n",
    "# Initialize a cart pole\n",
    "cart_pole = CartPole(Physics())\n",
    "\n",
    "# Starting `state_tuple` is (0, 0, 0, 0)\n",
    "# x, x_dot, theta, theta_dot represents the actual continuous state vector\n",
    "x, x_dot, theta, theta_dot = 0.0, 0.0, 0.0, 0.0\n",
    "state_tuple = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "# `state` is the number given to this state, you only need to consider\n",
    "# this representation of the state\n",
    "state = cart_pole.get_state(state_tuple)\n",
    "# if min_trial_length_to_start_display == 0 or display_started == 1:\n",
    "#     cart_pole.show_cart(state_tuple, pause_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "827602b4",
   "metadata": {},
   "source": [
    "Perform all your initializations here: Assume no transitions or rewards have been observed. Initialize the value function array to small random values (0 to 0.10, say). Initialize the transition probabilities uniformly (ie, probability of transitioning for state x to state y using action a is exactly 1/NUM_STATES). Initialize all state rewards to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9303536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Failure number 1\n",
      "[INFO] Failure number 2\n",
      "[INFO] Failure number 3\n",
      "[INFO] Failure number 4\n",
      "[INFO] Failure number 5\n",
      "[INFO] Failure number 6\n",
      "[INFO] Failure number 7\n",
      "[INFO] Failure number 8\n",
      "[INFO] Failure number 9\n",
      "[INFO] Failure number 10\n",
      "[INFO] Failure number 11\n",
      "[INFO] Failure number 12\n",
      "[INFO] Failure number 13\n",
      "[INFO] Failure number 14\n",
      "[INFO] Failure number 15\n",
      "[INFO] Failure number 16\n",
      "[INFO] Failure number 17\n",
      "[INFO] Failure number 18\n",
      "[INFO] Failure number 19\n",
      "[INFO] Failure number 20\n",
      "[INFO] Failure number 21\n",
      "[INFO] Failure number 22\n",
      "[INFO] Failure number 23\n",
      "[INFO] Failure number 24\n",
      "[INFO] Failure number 25\n",
      "[INFO] Failure number 26\n",
      "[INFO] Failure number 27\n",
      "[INFO] Failure number 28\n",
      "[INFO] Failure number 29\n",
      "[INFO] Failure number 30\n",
      "[INFO] Failure number 31\n",
      "[INFO] Failure number 32\n",
      "[INFO] Failure number 33\n",
      "[INFO] Failure number 34\n",
      "[INFO] Failure number 35\n",
      "[INFO] Failure number 36\n",
      "[INFO] Failure number 37\n",
      "[INFO] Failure number 38\n",
      "[INFO] Failure number 39\n",
      "[INFO] Failure number 40\n",
      "[INFO] Failure number 41\n",
      "[INFO] Failure number 42\n",
      "[INFO] Failure number 43\n",
      "[INFO] Failure number 44\n",
      "[INFO] Failure number 45\n",
      "[INFO] Failure number 46\n",
      "[INFO] Failure number 47\n",
      "[INFO] Failure number 48\n",
      "[INFO] Failure number 49\n",
      "[INFO] Failure number 50\n",
      "[INFO] Failure number 51\n",
      "[INFO] Failure number 52\n",
      "[INFO] Failure number 53\n",
      "[INFO] Failure number 54\n",
      "[INFO] Failure number 55\n",
      "[INFO] Failure number 56\n",
      "[INFO] Failure number 57\n",
      "[INFO] Failure number 58\n",
      "[INFO] Failure number 59\n",
      "[INFO] Failure number 60\n",
      "[INFO] Failure number 61\n",
      "[INFO] Failure number 62\n",
      "[INFO] Failure number 63\n",
      "[INFO] Failure number 64\n",
      "[INFO] Failure number 65\n",
      "[INFO] Failure number 66\n",
      "[INFO] Failure number 67\n",
      "[INFO] Failure number 68\n",
      "[INFO] Failure number 69\n",
      "[INFO] Failure number 70\n",
      "[INFO] Failure number 71\n",
      "[INFO] Failure number 72\n",
      "[INFO] Failure number 73\n",
      "[INFO] Failure number 74\n",
      "[INFO] Failure number 75\n",
      "[INFO] Failure number 76\n",
      "[INFO] Failure number 77\n",
      "[INFO] Failure number 78\n",
      "[INFO] Failure number 79\n",
      "[INFO] Failure number 80\n",
      "[INFO] Failure number 81\n",
      "[INFO] Failure number 82\n",
      "[INFO] Failure number 83\n",
      "[INFO] Failure number 84\n",
      "[INFO] Failure number 85\n",
      "[INFO] Failure number 86\n",
      "[INFO] Failure number 87\n",
      "[INFO] Failure number 88\n",
      "[INFO] Failure number 89\n",
      "[INFO] Failure number 90\n",
      "[INFO] Failure number 91\n",
      "[INFO] Failure number 92\n",
      "[INFO] Failure number 93\n",
      "[INFO] Failure number 94\n",
      "[INFO] Failure number 95\n",
      "[INFO] Failure number 96\n",
      "[INFO] Failure number 97\n",
      "[INFO] Failure number 98\n",
      "[INFO] Failure number 99\n",
      "[INFO] Failure number 100\n",
      "[INFO] Failure number 101\n",
      "[INFO] Failure number 102\n",
      "[INFO] Failure number 103\n",
      "[INFO] Failure number 104\n",
      "[INFO] Failure number 105\n",
      "[INFO] Failure number 106\n",
      "[INFO] Failure number 107\n",
      "[INFO] Failure number 108\n",
      "[INFO] Failure number 109\n",
      "[INFO] Failure number 110\n",
      "[INFO] Failure number 111\n",
      "[INFO] Failure number 112\n",
      "[INFO] Failure number 113\n",
      "[INFO] Failure number 114\n",
      "[INFO] Failure number 115\n",
      "[INFO] Failure number 116\n",
      "[INFO] Failure number 117\n",
      "[INFO] Failure number 118\n",
      "[INFO] Failure number 119\n",
      "[INFO] Failure number 120\n",
      "[INFO] Failure number 121\n",
      "[INFO] Failure number 122\n",
      "[INFO] Failure number 123\n",
      "[INFO] Failure number 124\n",
      "[INFO] Failure number 125\n",
      "[INFO] Failure number 126\n",
      "[INFO] Failure number 127\n",
      "[INFO] Failure number 128\n",
      "[INFO] Failure number 129\n",
      "[INFO] Failure number 130\n",
      "[INFO] Failure number 131\n",
      "[INFO] Failure number 132\n",
      "[INFO] Failure number 133\n",
      "[INFO] Failure number 134\n",
      "[INFO] Failure number 135\n",
      "[INFO] Failure number 136\n",
      "[INFO] Failure number 137\n",
      "[INFO] Failure number 138\n",
      "[INFO] Failure number 139\n",
      "[INFO] Failure number 140\n",
      "[INFO] Failure number 141\n",
      "[INFO] Failure number 142\n",
      "[INFO] Failure number 143\n",
      "[INFO] Failure number 144\n",
      "[INFO] Failure number 145\n",
      "[INFO] Failure number 146\n",
      "[INFO] Failure number 147\n",
      "[INFO] Failure number 148\n",
      "[INFO] Failure number 149\n",
      "[INFO] Failure number 150\n",
      "[INFO] Failure number 151\n",
      "[INFO] Failure number 152\n",
      "[INFO] Failure number 153\n",
      "[INFO] Failure number 154\n",
      "[INFO] Failure number 155\n",
      "[INFO] Failure number 156\n",
      "[INFO] Failure number 157\n",
      "[INFO] Failure number 158\n",
      "[INFO] Failure number 159\n",
      "[INFO] Failure number 160\n",
      "[INFO] Failure number 161\n",
      "[INFO] Failure number 162\n",
      "[INFO] Failure number 163\n",
      "[INFO] Failure number 164\n",
      "[INFO] Failure number 165\n",
      "[INFO] Failure number 166\n",
      "[INFO] Failure number 167\n",
      "[INFO] Failure number 168\n",
      "[INFO] Failure number 169\n",
      "[INFO] Failure number 170\n",
      "[INFO] Failure number 171\n",
      "[INFO] Failure number 172\n",
      "[INFO] Failure number 173\n",
      "[INFO] Failure number 174\n",
      "[INFO] Failure number 175\n",
      "[INFO] Failure number 176\n",
      "[INFO] Failure number 177\n",
      "[INFO] Failure number 178\n",
      "[INFO] Failure number 179\n",
      "[INFO] Failure number 180\n",
      "[INFO] Failure number 181\n",
      "[INFO] Failure number 182\n",
      "[INFO] Failure number 183\n",
      "[INFO] Failure number 184\n",
      "[INFO] Failure number 185\n",
      "[INFO] Failure number 186\n",
      "[INFO] Failure number 187\n",
      "[INFO] Failure number 188\n",
      "[INFO] Failure number 189\n",
      "[INFO] Failure number 190\n",
      "[INFO] Failure number 191\n",
      "[INFO] Failure number 192\n",
      "[INFO] Failure number 193\n",
      "[INFO] Failure number 194\n",
      "[INFO] Failure number 195\n",
      "[INFO] Failure number 196\n",
      "[INFO] Failure number 197\n",
      "[INFO] Failure number 198\n",
      "[INFO] Failure number 199\n",
      "[INFO] Failure number 200\n",
      "[INFO] Failure number 201\n",
      "[INFO] Failure number 202\n",
      "[INFO] Failure number 203\n",
      "[INFO] Failure number 204\n",
      "[INFO] Failure number 205\n",
      "[INFO] Failure number 206\n",
      "[INFO] Failure number 207\n",
      "[INFO] Failure number 208\n",
      "[INFO] Failure number 209\n",
      "[INFO] Failure number 210\n",
      "[INFO] Failure number 211\n",
      "[INFO] Failure number 212\n",
      "[INFO] Failure number 213\n",
      "[INFO] Failure number 214\n",
      "[INFO] Failure number 215\n",
      "[INFO] Failure number 216\n",
      "[INFO] Failure number 217\n",
      "[INFO] Failure number 218\n",
      "[INFO] Failure number 219\n",
      "[INFO] Failure number 220\n",
      "[INFO] Failure number 221\n",
      "[INFO] Failure number 222\n",
      "[INFO] Failure number 223\n",
      "[INFO] Failure number 224\n",
      "[INFO] Failure number 225\n",
      "[INFO] Failure number 226\n",
      "[INFO] Failure number 227\n",
      "[INFO] Failure number 228\n",
      "[INFO] Failure number 229\n",
      "[INFO] Failure number 230\n",
      "[INFO] Failure number 231\n",
      "[INFO] Failure number 232\n",
      "[INFO] Failure number 233\n",
      "[INFO] Failure number 234\n",
      "[INFO] Failure number 235\n",
      "[INFO] Failure number 236\n",
      "[INFO] Failure number 237\n",
      "[INFO] Failure number 238\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABpCElEQVR4nO3dd3wT9f8H8FfSTXeB0hYoLXvvDQKyFERZfl38HHwVRUFBRPziAlwgS0RlKQqICF9l+FWUoVAQBGVPGTLaUlpKge7dvH9/lDuSNm2TNpeU8Ho+HnlA0svlk8vl7pX353N3OhEREBERETkJvaMbQERERGRLDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIiciqujG2BvBoMBly9fhq+vL3Q6naObQ0RERBYQEaSlpSEsLAx6fem1mTsu3Fy+fBm1a9d2dDOIiIioHGJjY1GrVq1Sp7njwo2vry+AwoXj5+fn4NYQERGRJVJTU1G7dm11P16aOy7cKF1Rfn5+DDdERES3GUuGlHBAMRERETkVhhsiIiJyKgw3RERE5FQYboiIiMipMNwQERGRU2G4ISIiIqfCcENEREROheGGiIiInArDDRERETkVhhsiIiJyKgw3RERE5FQYboiIiMipMNwQERHdxjIzMyEijm5GpcJwQ0REdJs6cuQIAgICMGHCBEc3pVJhuCGHEhGMGDEC48aNq9B8Jk2ahIceeggGg8FGLSOqmFOnTqFbt274+eefHd0UcmJr165FXl4eoqKiSp1u8eLFGDRoEG7cuGGfhjkYww1VWF5eHt555x38+eefVj/34sWLWLVqFebPn4+srKxyv/7s2bPx3Xff4fz58+Wah63t3LkT06ZNw/Xr1x3dFHKQ77//Hn/88Qe++OILRzeFHGjNmjVYv369ZvNXQk1CQkKp082cORMbN268Y9ZHhps7yKlTp3D58mWbz3fTpk2YMmUKJk6caPVzjdsTHx9frte/cuWK2t+ckpJSrnnY2ksvvYSpU6eiWbNm/OVuA0eOHMHZs2dLnSY7Oxs7d+5EXl6enVpVOmXdrsh3TkSwZ88eJCcnmzyelZWFnTt3Ij8/vyJNLFVCQgIOHjyo2fwdwR7Lzdj169cxYsQI/Otf/9Lkh05WVpb6ozIxMREFBQVmpxMRdT1cvnz5HTE+h+HmDnHt2jW0bdsWHTp0QEZGhk3nfeHCBQBAbGys1c813vBbuxNQuqCMn1dWuLFXt9XFixcBFO4ghg0bVu7g5gwqsszT09PxwgsvoHXr1mjatCmmTZtWYnj54IMP0LNnTyxdurTcr2cJ4/djMBhK3FGUN9wYz3P37t3o2rUrnnnmGZNp3nnnHfTs2RPLly+3at7WuP/++9G+fXu7VkO1/n6+++676NmzJ7766iurnmdpu4pOFxMTg4KCAhQUFGDXrl1WvaYl9u7di9zcXPW1r169ana65ORkZGdnAwBOnDhhVWi9Xbv6GW7uEBcvXkRWVhYuX76MRYsW2XTely5dAlC4I7f2F0F5w83kyZNRrVo1nD9/3iQ4lBZu1q1bh8DAQHz++edWtdFaaWlpajtCQ0ORk5ODU6dOafqalVVSUhJq1qxZbOdsCRHBvffei4ULFwIA8vPzMXXqVDz99NNmpz9y5IjJv1oYNWoUatWqhaSkJBQUFKBjx47o0qWL2R2Asj7Hx8dbvIPIzs5GkyZNMHDgQADA4cOHAQDnzp0zmU7r92owGHDkyBGICI4fP67JaxR1+vRpBAUFYcqUKZq9hrK8Dh06ZPL4yJEj0bBhQyQlJRV7TmxsLIKDg/HKK6+UOu/XXnsNVatWNfmslG0jAOzYsaMiTTer6Dibkrqmim5bLQ3Fv/zyC/z8/PDNN9+Uq32OxHBzhzAeRDZr1qxyj28xR/kC5+TkWN0tVN5ws27dOty4cQPbt2+3qHJz/vx5PPXUU0hNTcX3339vVRutFRcXBwDw9/dH48aNAZS/y+1298cffyAhIQHr1q2z+rlJSUnYvXs3AGDr1q1YvHgxAJTYzRcTE2Pyb0lef/11TJ8+3er2AMCPP/6I+Ph47NmzBzExMThw4AD+/PNPs5+v8lh+fr7ZnaY5J06cwJkzZ7Bp0yZkZmaq7yU1NdVkOkvfa3lduXJFrZCVpyJbHr/++itSUlI0HZ+iLC+l2qz4/vvvcfbsWaxcubLYc/766y9cu3ZNXYfj4uIwYsQIHDt2zGS69evXIzk5GT/99JP6mHG42blzp83eh6JoYCppO6M87uLiAgBYtWqVWvEpzcaNG5GRkYEff/yxgi21P4abO4RxuLly5YpNqxfGX+CyBrUVVZ5wYzAYEB0dDaCwIlVWuMnLy8Ojjz6KtLQ0ANC8iqIsj1q1aiE0NBRAxcZd3M6U7rkbN25YHXyV54aFhaFv37544IEH1HmZG1tgyQ4/JiYG06dPx+uvv66uD5YyGAxqSLl48aLaPuO2Gk9rvKOx9PM3nk90dLT6XozbKiLq+m+LcHPjxg0sWLAAc+bMwbJly5CXl2cyX60CVFHKe7948WKpFeCzZ89i/fr15Ro3Yi7cZGVlIT09HQDMhhtlvFNsbCzy8/OxYMECrFq1yqTCZLxN2r9/v/q48bbx4MGDVq9zpcnOzsbevXsBAHXr1gVQduWmR48eqFq1Kq5du2ZR1c/4M1Hms2rVqkozrq00DDd3CGUwm7u7OwCov4Jtwd7hJiEhATk5OQAKN1JlhZv//e9/+Ouvv+Dn5wegcANn63FHxozDTVhYGIA7t3JjvBMpGgAsfW5ERAQAICgoCEDhjqToANv09HR1HS9tZ/zPP/+o/7d2LIlxqLpw4YLJeytaCbh69apJALN03S46T3PhJiUlRd0Z2yJ4vPfeexgzZgwmTpyIkSNHYvXq1Q4JN8p7T0tLK3Xw7fDhwzFs2DCrBzunpKSoFbCLFy+qXYXG41QOHDiAv//+2+R5yrpWUFCAS5cuqQPbd+3apQas+Ph4tRJSUrgxGAxqJdIWDhw4gJycHISEhKBHjx4Ayg434eHhaNKkCYDiXZ3mKJ+J8u/LL7+MESNGaF79tgWGmzuEUrlRvgRnzpyxSfo2GAxqNwxgn3BjvJMsGm6K7vSAW5WaYcOGoVq1agAK379WlA1azZo1Wbkp8llZQ5k+MjISQGEw9/X1BVA4QN6YcddJampqiVUi43Bj/H9LJCYmqv+/ePFiqcGt6OddnnBz8eJFNVhkZ2er31fjsHHt2rUKB3Vl/IkS/g8dOmTyGvbqliqtEqa4cOGC2h1kbbuM31NOTo66rTL+XAHg66+/NrlvXPW+ePGiut5cvXoVp0+fLtbe06dPqyFK2Rb4+PgAsG3XlBLCWrVqpW5nSvoRpax/YWFhqF+/PoCy138RUd9XYmIiMjMz1XWl6Jilyojh5g6hfEGbN28Ob29v5Ofn2+QoiKSkJJO+W3uEm6I7gLIqN8oXNCIiQv3VUvTXmbH58+dj3Lhx5T5KgJWbWypSuVGmV8INADWcFg03RasLJVUbbBVuLly4UGpwK2+4MZ7nmTNnTJ6nVG+Kvjdrd/JJSUl46KGH8NtvvwGAuoMeNmyYet+RlZui/ze2adMm9f/WdnMWfR/Kayifq06nA1AYboy3Y8Y/mC5cuGCy3ihHQBm3V0TUqpKyLVCWrS3DjfK5NWrUCCEhIQAKt7+nT5/GkCFDcOLECXVac+GmrMrN1atXkZmZqd4/c+aMus9QXrsyY7i5DeXn52P16tVmqxQlUcJNUFAQGjVqBMA2Y0+My66AdeEmPT3dZKBkecLN5cuXTXYI5jZ4Sl94RESEOsC3pPeenZ2NV155BfPnz8e+ffssak9RHHNTSEQs2mGVpGi3FABUrVoVQPnDjfEG3ZKyvLHSKje2CjfG89m9e7fJuBLlu2Lpey3J0qVL8d1332HKlClITU1V26aMaTp16pTJPC9fvqz5eWFSU1NNuqIcEW569OiBGjVq4NKlS2jZsiW2bNkCwDTc7Nu3z6SL8Pfffzfb3v3790NE1G3BI488oj7fVuNVlG1Y48aNTcLNnDlz8MMPP2DWrFnqtMbhpl69egDKDvdF39Nvv/2mdrXeDkd/MtzchhYsWIBHH30Ur732msXPUTYcxuHGFunbuEsKKBysbCmlmuHm5gag8JepJQPuilYAjANSWZWbssLNsWPH1A15eU9gpiyTO71yk5ycbPLZVLRbCrgVbooefWTvyk1ycrLJ0TIldUsp63ZZ4UZETLoBgOLrX0mVG2vDjTLfw4cPq9+DGjVqoEuXLgAK34vxCRMLCgo0X3+LLj9zVb6cnBy12gTYPtyEh4dj27ZtaNmyJa5evYrHHnus2PiurVu3msxDCTdKewMCAgAUhpvU1FS1y7BHjx7w9/dHbm4uTp48aVW7S2JcuTHullI+X+P1pzzdUkW/r8bB8vz585V+UDHDzW1I+YIbf9HLolRuAgMDy9zBW6MilRvlCxcZGamOpbBkI1raTrLoBs/4KAbjbqmS3rvxBqG84cZc5SY9Pd2mR0rcDop+TtZ0Sxl/bubCTUmVG71eb3LfmIiYVGsqEm4A01AdExNjUt1Q1u2WLVua3DdnyJAhqFu3Ls6cOWNyioai3aJFKzelvdfSKOu18SG+jRo1Qo0aNeDn5weDwaB2aShdNVqPuym6rpj7ju/evdtkfFF5w40SQJTXUAYUBwcHo2nTpvjjjz8AFK5jycnJJmNulHWmXbt20Ov1uHDhAuLi4tR5DR48GEBhuFG2A0FBQfD29kbbtm0BlH+7Yiw3N1ftIjKu3MTFxamh++TJk8jKyjI5O7Fx5SYhIaHU8VpFv6/GXWr5+fk4d+4chg4ditDQ0BJPHuhIDDe3GRFRv3znzp2zuFJiHG5sWblRvsDGXxhLGX/hrKlwKF865egZY0U3eAkJCcjNzYWLiwtq1qypBrszZ86YPZz4wIEDZv9vqezsbLWqULNmTfj4+FgV3JxJ0c/pwoULFh++qxwRp9frUatWLfXxksKNEoRat24NwPwO/8qVKyYb80uXLqlnbbVE0XADAFWqVIG7uzsKCgpMqpjKut2+fXsAJX/2BQUF+Omnn3Dx4kX15JqBgYFmp1XCcdH3qty3REpKikmoW7VqFYDCHaROp1O/H4oWLVoA0H7cTdF1xVwQ/uWXX0zuG3/XRQRTp04t9QSlynK66667ABSv3AQHBwMAvL291e9sUlKS2e7/tm3bolWrVgAKx90o7X3wwQcBFG6blZChrL9KuCnPdqWoc+fOoaCgAD4+PggNDVXDTVZWljoGsqCgAEePHsW1a9fUKktISAgCAwPV5Vxa16yyfJRpi54XZ+fOndiwYQMSEhJMzu1TWTDc3GbOnj1rUpJXgk5ZlG4p43Bjy8qNshGvaLgpq3xfUFCgbmh79uypPu7t7Q2geLhRNjq1a9eGq6srwsPD4enpiZycHLMbUONfVcePH1cPObeUsoPz8vJSd1KVadzN9evXy3WB0/JQNo7KEXrp6enFQklZz61du7batQOUPaC4e/fuJveNKTv1iIgI+Pr6FhsTBBTuJHfv3m0ykFJhLtxERkaiTp06Jm0GioebhIQEs2FaOdMxcOussc2bN1dDnLGilZvS3mtJih7lovz6V7YJyr8A4Ovra3G4ERFERUVZFRaNKcuuV69eAIqf60ZE8MMPPwAAunXrBsD0u/77779j2rRpeOGFF0oMkkW3GyWFGwCoXr06gMKqjrlwU69ePXU+P/74ozrvNm3aoGHDhgCAZcuWASj8kQPAppUb4/E2Op0Ovr6+6jbQ2MGDB9V1sXr16uqpQCzpmlKWj/F2Fri1rf3000/Vx5TxSZUJw81tpuh5EiwNN8YDipUv3/Xr1y0+c2pJlHDTrl07AKVfvK2o8oSbuLg45Ofnw83NDV27dlUfV7qbSgo3yqBUFxeXEsNdbm6u+mvLzc0NeXl5JkccWMK4S0op6VemcTdDhw5F586d1R2FlpSNY+PGjdWAZ2nXVNHPTWGucqOcfwQoI9ycPQsdgPr16pW4cZ8zZw66d++O9957r9jzlZ2gUqUECsON0kbj96asx61bt4Zer4fBYDAbjozXd+U7ajxPY2lpacjLy1OfU55wo+xYjQMjALViY1y5CQ8PR3h4OICyu6XmzJmDu+++G2PGjLG4LcaUZdejRw/odDpkZWWZLK/Dhw/j7Nmz8PT0xGOPPQbA9Lu+Zs0aAIUhyNw5WPKzslDl0iWMB/D0hg24COBEdDTyjh5VX6dJfDywejXw668Y4O6OjgDS//4bKUbdUormVati2NChAID//ve/KCgogLu7O0JdXDDsZtfU5s2b0RzAtNOngTFjcO/mzVgBYNaff0IaNwaCg4ENG27N9MYN4IMPAAu+I8bjbRRK9Qa49fkahxtlOwTAoiOmlM/k7rvvNnn83nvvBQCTMWdbt26tdNegYri5zShhpnbt2ur9JUuWoF69eiUGnYKCAvVXX2BgIKpUqaJutCraNaXsVNq0aQOdTgeDwYDfvvgCM4ODsWvJklKfW2K4EQGuXi28KWJjgb594Tt0KP4HYIq/P1rcPHcEcCvcZGdnm5RPze0klQ140TN0njx5Erm5uQgICFBL19b+yjION4rKUrn5448/1H7zGTNmaP56xodyK8vf0kHF5gYTA+YHFCeeOoVeeXl4X6dD55uVkri4OOSfPg1s3Vq4w5owAUPGj4cBwNbffsP+Q4fgDaON+4cfwtC3L/ymTMELAJK2bStcD40kJibCDcCy/Hw8AqAKCteryMhIeADQ/forcOoU8vPz1e7iehcvIrxGDQC3Pv/Zs2ejWbNmiI2NNbtO1K1dG0M9PbEAwIcAHr55/pm0tDRcvnwZ/gYDqri5oUOHDgAKg4elOxZlfVbGhijMVW7Cw8PV7UxpASonJwdz5swBAKxYsaLYQQaWUD7vhg0bqt8d43VFCS/33Xef+ncl3BQUFOD777+HN4AwAOtXr74146lTgapV4VqlCk6J4CMAAbt2oQ6AfACxnp5quGmwdSvw6KNAv3749NQp/AngnlGjcC4rC68CCDUKD32nTEH3F17AW35+GJKXh1EAvvb0hL5hQ4z28lKnawqgw/nzwIIFCFqxAo8D6GYwQHf6dOH2zfjH5X//C7zxBhAZCTRoADz8MPD448CYMcDKlYDRmC7Djh0YD2BESgrw7bfAtm14xNUVYwB0BTD05pFvJYWbso6YMh7zZhxudDod7r///mLTX7t2rfKd+0buMCkpKQJAUlJSHN2UcmnatKkAkLlz5woAcXNzE3d3dwEgERERkpaWVuw5SUlJAkAASG5uroiI9O/fXwDIF198Yf6FUlNN72dmiiQkiFy7JpKSIpKZKYacHPH18pL2gJw9cUKCg4MFgBx1dxcBJB8QefxxkR07RPLzi73E+BYt5BIgWb6+ku3pKZmA5Or1Iq6uIoDIxIm3Jj51qvAxo5tBp5PlgNQB5P3331ffY2Jiovq0UaNGSRVAvnvwQZEnnhBp2lRWvP22AJCgoCCJj44Wyc4Wyc+XL774QgBI7969ZdKkSQJARo8ebdXnM2PGDAEgjz/+uPrYK6+8IgDklVdesWpetjZ06FB1GQGQ3bt3a/diBoMMqldP2gPy+/Ll8n+PPCIA5MMPPzSZ7MyZM/LFpEmS+vbbIrNmqbc1HTvKp4AkVq8u8uWX6vR/zZkjHwMyp0aNwnWrdm2TdaJgzx5xc3MTAJL6738XW2eMb56AjBkzpnDG/foVnyY4WKR+fZG77xYRkcDAQAEgl+vUEQEkC5ALDRvKuQYNJFN5zoQJEhcXJwAkXK8XASTJ1VXeAuT3mTNlz8aNUh2QcECWzJ0rS5YsEQDSAZB5gPwOSK6Hh0k78gEJAGTatGmyc+dOWQhImk4nBffcI98B8l9AMgcNEnn6aZH160Vycm4t4FOnRK5dk6VLl8rWrVulSePGAkB++OEHdbvh7u4u+Te/n8ePH1fXj+eee05++uknASBt2rQp8aP+6quvTNar1157Tf3b+S1bZO20aVKQlVXKqmIQPz8/ASAnT56Uu+66SwDIt99+W/j3nBxpEx4uAGTNmjWy49dfpQYgzRs0ELl8WY69+aZ8B0j2zeXVF5DY2NjCmb/1lroccwDZ7ekpMneuPFa7tkQC8uuvv6rL4cZLL4l07y7SvLnEBgRINCB5Nz/DGEDuvbnNBCAFERElrleGQYOkfv36AkAaArL34YdF3n5b5LXXZGGdOvIQIJtef13k6NHCbani559FevcW0enMz/vyZXXSFaGhpa7bf82ape4f3nrrLQEgTz/9tPr85cuXq9s65TP44osvZNu2bSIicunSJQEgLi4ukpeXJ1WrVlX3MYcPH1aXg5eXl9xzzz0CQKZPn17iZ2wr1uy/GW4qmby8PImNjTW5FRQUiIjItWvXTHbgSpgwvo0aNcrkudnZ2XLmzBkBIL6+vurrvPjiiwJAnn/+eUlISDBugKR+8IEU+PtLwo8/SmxsrKSnp4usXVvqlyn711+lZcuWAkAGAXKiyN8LfH0lLzxcsiZPVl+qZd26klHKPNMfeUR9H5dOnpSkTz6RrwcOlPGAnDL6chcAsm3cOPHx8REAkjBjhsjw4SLDh8ueatUkzXi+DRpIbk6OtGnTRgDIP/7+hRskFxeJDQiQtYAcaNJE/undW94GpG3btmob4s6eFYPBUOJnl5iYKCNHjhQAMtnofc6ePVsAyKOPPqo+lpuba3Ze6enp6v8NBoNcvnxZYmNjTUKruXXE+BYfH28yz6tXr8revXtFp9MJAOnVq5cAkGHDhpm0p7R5GgdGSU4W2bBBDC+8IFm9e0vq009L8qRJkrhmjWTd3IkZ1q0z+Syz3N1lIyAXgoNF3N1FFi+WlStXire3twwrZR0QQGTrVvWlL77zjtlpzgHyc3CwyNGjUrduXQEgF557TqR5czH06iXpDz0k4yMjpRogG7/6Sr65+Zn06tVLYmNjJWHzZpkaFiazAPkFMFkvDS4ukpOaKgBEB8g///mPnDXThkQ3N0l5+WX5+eefBYDcGxwsUspOaMUDD8jUqVMFgIy8uRNVbhm+vvIpIEsBiQ8IkB6ATJw4UVauXCl/lrasvLxEjH/gtGolBr1eogDZhcIAEAtI1n33yczatQWANGvWTJ08Oztb9Hq9AJB1jzwiSQ8/LJ8C8oCfnzpNVkqKXP7zT7ny3/9K2mOPyQ0XF4kG5LifnxwGJCAgQF1fdwYHFwY0FxeR1q3F8NRTkj9vnshff4lcuSKZmZly4sQJdfuVmZkpTzzxhAQCsqVHD8mtV08K9Hr5GpAqVapIenq6RBsFlqK3PJ1OegDyzjvvyOXLl8UQGyty/Lh8v2iR6ADp2bOniIgMGDBAAKg/RgBIRkaG+h5fffVVASAPDBggfQH5yN1d/nPzu12jRg2RGzdE5s2TGx06yPab68zPrVsXBpSCAnnjjTfU+W7evFmd70svvaRup+Pj4022AUlJSRIbGyvJFy8WzmfuXDHMni2pzz0nOa1bS05UlLpdeLpKFVkJSHLfviI9e4o0biznQkLkR0DO6XSSn50tgYGB4gPIW5GRUhuQt956S32t3bt3CwCpU6eOiIgcO3ZMbe8rr7wi69evV8OMiEj79u0L1+l775WMjAx12nvvvVc+/fRTASB33/wRkJOTI+fOnZOrV6+KrTHclKIyh5u9e/dKREREscAyYMAAERF1o9mwYUMRufVLPDAwUFauXFnseQAkNDRUfvvtNwEg4eHh6mt99tlnAkAWA/IFIH+1by/y+OOSUaWKuqH4/OY8qlSpIlfffLPEDUqyTieyapVaDVJu7QBJHTZMMjw91Wn36nSyZ88eSUtLE09PT2kESPTPP8u+b7+VcEBq3rx5mHkvxrcPPvhAZN8+2ebqKvmA7PzuO6lZs6YAkPjHHivWxsywMJFXXxW5Wa04evSouLm5SXQpO4rjRV5zLyAFOl1hZalvX5EffhD5+mvJHj1aPuzUSZ1OB8jxbt1EliwROX5cVt38bHr16iUiItHR0RIcHCzDhw83+fw///xzMf4FNHr0aHWenp6eEj91qhieeko2BgbKQkCeR2GQ7IfCSoBxW5VwpczTeF1SdiY6nU6io6MlNzdXGjZsWGwZVwWkvtH9hW+/LdK1q4iLi9nl9dHNDX9ycrIknjkjKYBEA2Iw+vyV264nnlDne5enpywDit3mAnLi/fdFjHY6l7dulRmAfKvXS8zjj0s/vV58b87nscceExFRw9s333wjIiKDBw82eV/Hjh2TqKgos+uVj4+PuLm5iScglzdskFVjx0pHvV7+u2qVKL9kMzMzBYA0BiR24kS58PLL0tTMvDp27CiSmytL+/SRjYDEGa+PgMzt1Emee+45ASCj+/WTjwD5P0Ditm6Vn3/8UQBItWrVZNq0aQJAnn32Wfnggw9EB8jb990nsmiRzK5bV56/uS584uoqyUYVQxEprDqVsH4fuVkNGT58eGFF1stLJChINnl7y/Yi03ZF4c7/xo0bMstoG2HuFgzIggULRETkax8fSS5huvzgYKlevbq6vJZUqSLyyCNypn79Yj96ngbk4YcfFhGRmO3bbwVPnU6OurjIh4DsWbRI5s+fb/IZKJW56dOnC3Crovrmm28KAOnevbv6uRubOXOmKNtaJQQoP1K6deumTmcwGCT85nI0rlwcPXpUbcPx48fVx5WKiXGQEBFZunTpre2HTiebNm0y2cYr2/L09HS5cuWKOl1mZqY67/fee08ASI+77hIRkT59+kjkzeU0FJCFCxeq0yYkJKjzyM7Olq1bt5r9PiiB5V//+pcAkHHjxomISJ06dQSAzJkzR/3x7ObmJpmZmWr1r2rVqmJrDDelqKzh5ptvvlHL6S4uLuLu7q7eV754Sgl70KBBIlIYdurUqSMbNmwQEZHXX39dPD09xd3dXS21Aih8HJD5ISEikyaJiMiFCxekdu3at8rpRrcEQF7Q68XDzU39tT9nzhwRg0EkP19WffmleKOwVB7m7i4Tbq7wTxjtsJTb8uXLJTgwUJoC0k2vl7aANG7cWEaNGiXKL4O8vDzJyMiQVq1aqW0v7RYaGipHjx4VEZEJEyZIz8aNJSUlRe2y2zdvnsiCBVLw6acyxsVFOgJy8cKFYst8/vz5UqNKFanm5ib13NxksKurTA0OlvR33pGCd9+VT5o2VV/Tz8VFLXubu3188/26u7tLnxo1TP6W6+MjGwFZHhAgMm6cfPbgg+rGIOfKFZExYyRx+nTp5ukp7oC4urrKhx9+qC5D5Zf00TZtSt2ptHRzE1dXVwEg99SpI/LHH/Lv7t3FBxBvvV76BATI1QEDRJ54Qtq1aycA5Pvvv5f09u0lBpAkFFYssgHJvTnPnTqdOs+e3buLBASIAPKPi4t8CshoQObr9bJCr5eHceuX6rZt28QNkMjISJGCAvnnv/+VsYA8otNJzLZt0jQyUt1YpqamyrPPPitVqlQx+Zxbt25t8mtapLCypSwXpfqo1+slICBA1q9fLyIiTz75pCgB2GAwiKenp7q8u3fvrq5vrVu3Nnm9KlWqyKxZs9Quhe3bt0vHjh0FgHTo0EGAm7/aReTxxx+Xzp07S05OjmRlZUn79u2LzWvevHkiIrJ582YJCgoqXHcDA2XczXa3a9dO7r//fgEgixYtkuHDh8uQIUOkoKBAkpOTpVmzZvLKK6/IRx99JEBh5W/s2LFiHF4XLFgg3t7e6vd08eLFxdbz6c8+K6MBeadePelds6YsGzlSZM4c+ef996V+/fry008/FYabIutTgaenGF58Ud53dxcXQE6dOiVRUVEy9eb6EQPIKr1eBnh4yIoXXhD5739l8b//La4orEzk5+eLi4uLAJDOISFybvZsmQbIRkAyqlSRrJufi16vlyB3d8l2czN5/UM6nTzh4iIRbm5SrWpVtRv1WlKS6G9ufy6fPq2uDzk5OZKUlCSNGzdW11mlMqFUVKdMmSIiIj/eDI/Kd6tu3bomy0zpalPm06pVKzl58qRERESYhARl2vr168vp06fVxwwGg/zf//2f9O/fX/Ly8tTHr1y5IvXr11e37TVq1BCDwSC9e/dWw4YSOC9fvqzeV2779u2Tv/76SwBIWFiYSTsOHjwoderUkWXLlolI4T6lgY+PbNHpZFhwsPzzzz8m7VPe++XLl2XdunUCQEJCQqR27dri7u4uPj4+6rCFtWvXSnh4uPz+++8iUtj93rp1a7X65OXlJQDkwoULsmfPHoHy3bcxhptSVNZwo5TShw8fLsnJySJS2M2hrNQFBQXqL4cRI0ZYNE+l9PpG8+YSo2w0XFxEzp5VpzHMmSNzq1WTKYAsDg2VXoA0rFtX7QqbdbPv9r777lOfo/yaePPNN01eTxmnAkD9sjZv3lyUX6CJiYkSEhJi8mXdsmVLRRedqkuXLgJA1q5dKyKijn1Q+o0r4vTp0+INSH0fH5G//xYZP14kLEyiQ0JkDiBPBgfLvn37Cie+eFHkjTdEevUSMfMr93UPD/X9//P556Y7lJs7jtybIeP9J56QTz75RADIhLZtZfd998l4QFZFRIjcd59Ix44izZuL1KkjYjCoXZf7SglB0r27GkTfffddySsyxsPk9sADcuTIEQEg/v7+Yti8WZ7u21fd4J85c0ZdRg/eDG2zZs1Sd8hDhgxR/66sE0qwCggIMOmGs4TBYBCPm8tPWbc+/fRTk2mmTJkiuLmDNf6FmmM8FqUUSgXy888/Vzfayq1FixZWtdccZXkGBQWpy+LHH38scXplLNh9990nw4cPFwAyf/58k2mUbpQXXnih2POVAFV0OZnIzy9cb//8U+Sdd0ReeUXk5g8C5UfDli1b5OuvvxY3QHrfrEIWtWzZMgEgffv2ldjYWJNlp/z6ByBhoaESUqOGAJBVq1YVPvmvvwqrq3PmiBw+XPhjyoy8vDx1Ptu2bVO3L8auXr2qTpOenq5uG1avXi0ipttWANK5c2eT5yvhR7kp3Vm2kpWVpYbuAwcOqOv0N998IwDUoA1AOnXqpIbrH374QTZs2KAG7orw9/cXoDC0KhWl/v37l2teNW5+lkeOHJHNmzcLAGnZsmWF2meONftvHi1VSSgj9mfMmAF/f38AUE8kBZheh0m5em9ZGjdujJoAphw/jtoArnp5AStWAHXrqtPoJkyA17vvYhqA5+LjEQVgzLhx6tlP+/TpAwDYsWMH8vLykJ6erp5Ma/jw4SavpxyK2LhxYzzzzDMACs8VAxQegly9enUsXLhQnf6ZZ55Bv379LHovllCWm3IUxf79+wEUHrnk6upaoXn7+fkhA8C5jAwYGjYEPvoIiIvD2A4d8AqATlOnquc0QZ06wHvvAdu3A8nJyNixAy8C+ADA2oYNsdPo3DnHk5JwdvBgbAWQhMLDF91u3jwATLp+Xf0MFpw8iXcLCjAPQMzo0cBPPwF//gkcOwacPg3odAgKCkKDBg1wAUBKUBDSjd+Eqyvw2GPArFm3LiB68iS++b//QzsA/3ngAeDChcIj02JjgcxM4Icf0LhxY7i5uSElJQXRDRvip5uHgC5YsAANGjRQZ6+c1OzIkSPqkWjKYwAwfvx4ALdOYvbss8+aPTdHaXQ6nXrElLJuGb8GAJNDs5UjbmrVqqWe46MsyhFaW7duNTljMGB6LpTyUuZ//fp19TIHxkeyFOVndLSUch4p48N+AdNlX5RykVjlMzfLxaVwve3YEXjrLWD2bODmcjQ+HDw2NhZ5AGrfPLdPUcbLvujh49999536/8vx8Ui4cgVhYWHqie/QoQMwcyYwYQLQqhVw81QKRbm6uqrrjXI6B+WIREW1atXU9eT06dPFlkH16tVR12g7qJzXpqT7ylmNbcXT01M9lP/9999HTk4OwsLC8OijjyIiIgKZmZl45513ABRuZ5Vz5cTFxalHoymPlZfxeqWcINJ4n2MN5XlpaWlW76e0wnBTCeTn5yM9vXA3ZPwl8vDwUM9XkJqaavUK2KRJEzyJwh3lHgBvPfRQ4c5Nb/qxP/744+oJ5/z8/DBy5Ej1b61atUJgYCDS09Nx4MAB/PLLL8jOzka9evWK7VQeeugh9OrVC7NmzVKvU6NQgtCQIUPwn//8BwMHDjS5sJstGIebzMxMTJgwAUDxw14rMm8RUT8r4NahlMp5I4pxc4N3jx64/thjeAPAg2fOYBdunYzu96QkfFitGvoDeH/cOCAxEb8uX46BrVrh4I8/wvWbb9TTq2dnZ6vXd+ndu7fp63h4qP/t1KkTHgLQPigIvgB6d+oEpKUBGRnAN98AnTvfugzF6dPYmp2NgwD8O3cu3KHVqlV4u3lIq7u7O5o2bQqg8IRlV65cgaurK9q0aWPSBOMd7NGjR00eAwoP41UOQXVxcSn3OVGUZadQTjSnUMLDxYsXSzxfTmmU5//888/F/maLcOPr66vueJUdQdGdc9HpgcIdh3KupKLTK8v56NGjJoeFZ2dnqyfqKzXclEIJNzExMeoh4coh4kUpyzk6OtrsOY3c3d0xceJE9f7YsWOLnXPHEsr3UTmVRdGwB9x6v1FRUUhOToZer1fP8QUAnTt3Vv9f9HMtGm5KOmt0RSjf4XXr1qn3dTqduq1UtvfDhw9Xw68W4aY8+5bS5sVwQyrjk1EpX1qg8FdqRVaaJo0a4d83/78QgG+RL6zC29sbY8eOBQCMHj3aZAXX6/XqeQ62bduGtWvXAij8wumK/LKqWbMmtm/fjkGDBqFOnTqocfP8HoGBgSY74+nTp2Pjxo02/zVkHG6mTp2Kc+fOoWbNmnj33XcrPG9PT0+1+qN8DgaDQd1xlBhublqxYgXefvtt6HQ6hISE4M033wRQGAS2b98OAOjbrx9QvTr6PvEEfj58GG0HDQL8/KDT6UyWn7+/f7FgYaxTp04AbgWv1l27Aj4+gFHlwvj6YsqF/Erb+SnXSFpy89xFLVu2hJfR+TyMp/n777/Vkx8ahxu9Xo9XX30VQOFVkpWdprWMz94bERFh8p1RHgMKd7DK52NNuFF+0SshVm/0Y8AW4QYwPX+PXq8vdb7K9zE1NbXEyk2jRo3g7u6OtLQ0k1Bx9uxZGAwG+Pv7mw0AllCCjFK5MX6sqJo1a8LV1RV5eXnqmbCNKyT9+/fHq6++Cl9fX/j7+2PUqFHlapPymZdUuQFurc/r168HULjMPT091b8r3xOg7HBj620VcKsqrlC+48YV8TZt2qBu3bpqkLl8+bLZ89aUhy0DiS2Dkq0w3FQCyum9vb29i/2KqUi5r0VyMuoBSAWwFuavxaSYMmUKduzYgffff7/Y35Qv3ZIlS9QNRdEuqaJ0Op36y+iBBx4o168zaykbvBMnTmDu3LkAgIULF9rkF4ROpyvW7RUXF4ecnBy4urqWuLFXuLi4YNq0aTh9+jT27dunnl159+7dOH/+PFxcXNQTB5pjHG569uxZajeb8Ubb3H2g8CRebm5uyMzMxOHDhwGUHm6UkKJ0BZmbZ3h4OAICApCfn4+cnBz4+voWCxXPPvssdu3apYak8jAON0Wrh0DhDtbFxQW5ubnYs2cPgOInAyxN0WmH3jwTLaBNuAkJCYGLi0uJ0yrr7+XLl9XLQhQNKm5ubmp1zbhrSgmuTZs2LfZjxFLGlZuywo3xd0E5YeTQoUPV7djw4cMRHByMQ4cO4eDBg8WqcJaypnKjnNW96PpdWrjx8fGBh1E1VItw07ZtW5Ntk/Id79SpkxpclO2sFt1SxqGZ3VKkCWVnae4LVJFE7F+1Kn53c8NqAJkovbTq4uKCHj16mN1pKr8woqOjkZubiyFDhqhnRy2N0v30xhtvWNTeilKW38aNG1FQUICOHTuaPZtmeRl/FsCtykhkZKTFY3oaNGiAWrVqoXnz5tDr9eqYjnbt2pW6MTD+lVf0F19RrVq1Mtkwmwsirq6u6ngZEYGbm5vJZQXMzdNYx44di02j0+nU6g1Q2F2kL9IFqtPp0K1bN1SpUqXU91CassKNuR1sebqlFKNHj1aXpxbhprQuKeDW911ZV3x8fOBjdHZuhXHXlMKi8TZlMD5LcVnhBri1rJWQVbduXcyePRsjRozAQw89BKAwXBtXdKylhBvlLLqlhRsRAYBiFwVt3bq1Og6r6Oeq0+lMgpcW4cbV1VW9lla9evXUa5Tp9XrMmzcPQ4YMwejRowFA024pW4y5YbcUmaVUbsoKN1avNN264c0uXfD8zbvl7Tdu1KiRuiN888038f3331v0K7Bz587YuHGjyaBTLSkbPOXXbbFxKTaavxJGlVP3l9UlZY6Xl5dJ/3/R67cUFRERgTZt2sDd3R0DBw4sdVp3d3e12yo4OFjdaBZlvMNr0KBBqQGtaIgwF5iKTmcueNhCWeEGuBUelO+MNeEmKCjI5DvWsWNH3HPPPQCK7yDLyzjclNW9UPT7XlIYMjeo2BbhRqncXLhwQb3+VWldisp7U8b+1K5dG88++yxWrlxZoVBrTNlWKsHF3DIp+lkVXQYeHh7qRSHNLR/jriktwg0ADBs2DIBpdRAA/vWvf2H9+vXquq51t5Qtw01l6Zaq2CEkZBOlhZuKlvuaNGmi/notrVuqNDqdDjt27EBSUlKxwZuVSdGxF8qvIlspqXJTWsWjNK1atVLHDJQVboDCC/HduHHDojDVqVMn7N27F506dSoxiBpv0Mva+VWvXh2hoaGIj4+Hn5+fyTWIjNkj3Bj/oi7pNYqGGWu6pXQ6HSIjI3HkyBFERkbCz88Py5cvxz///KNeILairAk3RXcSJY2d0SrcKNdyysvLA1D4PShtG1R02Zd3bFVpin7XzS2T8PBwVKlSRf2xY24ZrFmzBhcuXDA7hs043GgxoBgAnnjiCTRr1qzM7aqyjtwwuognu6VKx8pNJWBt5abMFfDYMWDiROD6dZMvdEW+oKGhoZU62ACmGzwXFxd069bNpvNXPgulclPmkVJlUHZGrq6uFrW1evXqJtWe0rz00ku455578J///KfEaawJN8Ct9nbo0KFYd1PRaYr+35aUX7M+Pj4lhhbjHayLi4vJhUwtocxXeQ8BAQFo3759ucetlDR/oOxw4+bmZjIQtqzKzfnz55GYmIiMjAycOXMGANTxOOXh4eGhHhwAlN4lBRQPN2VNXx5Fw425ZaLX601CuLl1PDAwEG3btjX7Gvao3Oh0OrRv396kG9kcf39/k6qXt7d3hcODuWqLLQYUM9yQytJwY/EK+PbbwJw5wMsvm5Rmtfr1UVkYb/A6dOhgdlyCLeavfHkr0i0FQC2J9+3b1+ZtrVu3LjZt2qQOXDbHeGNvSXeLUl3q379/idM0a9YM1apVQ1BQkGZhWAl4Xbt2LTFkGe9gy3OeI+WXvK0DsqJOnTpqUCprzA1g+oOmpMpN1apV1c+xW7du6NatG3JyckrtmrSUcfXFmnDj7e2tyXbHksoNcGsdDwkJsTqgaD3mxho6nc6kUhMWFlbhoG085sbiH85lzKsydUtVmnAzffp06HQ69URf5kRFRUGn0xW7KaX925Ul3VIWJ+K8PGDz5sL/T5hgs8rN7cB4g6cEB1sy/gKLSIUrN127dsWff/6JlStX2qyN1jCuAllSuXn55Zexbds29fxB5nh5eWHPnj3Yu3ev1Sfos1SnTp2wY8cOfP311yVOY1wZsaZLSvHqq69iy5YtePHFF8vVxrJ4eHioFRtLwo3xd760Q7pXr16N8PBw/PPPPzhy5AiCg4Oxbt26EkOgpYwDTVnhxnh5165d22bVLmPG33UvL68St4lK2CvPWCl7VG6sYVzhq2iXFGDbQFIZu6UqxZibffv2YcmSJSZHWpTm9OnTJguu6DkJbjeWVG6uXLmCgoICk8fMOnIEyMoCAgOBFi1QW6fDo48+Cp1Od0eFG1uPtzGef0pKCq5evYr09HTodDqrBqsWZe6oI3vx9vbGCy+8gPPnz1v03XNzc7NobFB5w56ldDodevToUeo0xp9JeT4fLy8vm54925wXX3wRGzZsKPO9AKY7ndLCUKtWrbB//348++yzyMjIwBdffGGTMS/G8yhrfqGhoXBzc0NeXp4m420A0+96SEhIiQHqoYcewtq1a/Hcc89Z/Rr2GHNjDeNAY4twY8sxN5WxW8rh4SY9PR0jRozA559/jvfee8+i5wQHB1eKJG0rloQb5fA/AKX/Iv7jj8J/O3cG9HroAKxatcpGLa3cqlevDnd3d+j1ek26E4y/wErVJjw8vMz+8srss88+c3QTNBEWFqbuYCsSPrX02muv4bXXXrNoWksrN0Dh90A5H5WtWNMt5eLigvDwcJw7d06T8TZA8XBTkkaNGqnncbKWEm70er3Nu43Lw7hyU9EjpQDtj5ZydLhxeLfUmDFjcN9996Fv374WP6dNmzYIDQ1Fnz591LO7liQnJ0dNk8apsjKxpFtKCTe+vr6ll5hvnrQMpYy1cFbe3t7YuHEjtmzZokl/r3HlpqJdUqQtZQcLlK9bqrKxtHKjFWu6pYBby9welRutlocSbgICAjTpWrOWrSs3SvhITEy0rFegFOa6pe7oMTerV6/GwYMHMX36dIumDw0NxZIlS7B27VqsW7cOjRo1Qp8+fdRDnc2ZPn06/P391ZtWvyQqwpLKzaVLl0zul0gJN0Wu7XSn6Nu3b6ln+q0I418nyjV2KjpQk7QzZMgQBAYGWtTtU9lZU7nRgjWVG6Dwem4+Pj5W/Wi1hqWVm4po1aoVatWqhQEDBmgyf2tp1S2lXK8MKKNXoBTK+pmUlIScmxcGdnTlxmHdUrGxsRg3bhy2bNlicphjaRo1amRyaF+XLl0QGxuL2bNnl7gBmzx5sskAyNTU1EoXcCwJN8p1bkpNw9evA1euFF4Y04FjOZyVcbhRTqRli40MaWP27Nn48MMPS720we1C+d67uLiU+5IFFaF07Vl6WP3YsWPx/PPPa7bs7VG58fPzQ3R0dIUHY9uKVt1S+fn5AApPrVDe91p0PwU4vnLjsHBz4MABJCYmmpwUq6CgADt37sSnn36KnJwci74YnTt3LvVoEw8Pj0o/JsKSbilFqWk4KAhISQFOnwYcvGI5I+NuKVudJZS05QzBBrj1vQ8ODnbIewoODsb8+fPh7e1d7IKpJdGynfao3ACoNMEG0K5bSlGRMFL0uV5eXlaffsHWHPbqffr0wbFjx0weGzlyJBo3bozXXnvN4i/GoUOHHNIHbUuWVG5Kul+MuztQyU+2d7syV7lhuCF7UHYejuiSUmh1WHx5GG8Hb/ftv6XCwsLUcUC22O4UDSQVCTdFB1w7uksKcGC48fX1RfPmzU0e8/b2RtWqVdXHJ0+ejLi4OKxYsQIAMG/ePERERKBZs2bIzc3FypUrsXbtWqxdu9bu7beV/Px8dXS5JeHG0aW+O5lx5Ub5RcdwQ/agbAccGW4qE1dXV/j4+CA9Pd3k7MnOzN3dXb20hpubW4Xn5+HhAXd3d+Tm5gKo2L5Fr9fD19e30hwpBVSCQ8FLEx8frw7cBIDc3FxMnDgRcXFx8PLyQrNmzbBx48YyLyRYmRkfvVX0rJuAFd1SeXlAt25Ay5bARx+xW0oDyrLPzMxEdnY2AIYbso+BAwdixYoVGDlypKObUmk8//zzOHTokGaX+aiMbF2l8vPzQ1JSkvr/ijAON5XhR3ilCjdRUVEm95ctW2Zyf9KkSZg0aZL9GmQHSpeUt7e32TRucbg5cQLYtw84cwZYssTWzSSYLnuDwQC9Xo/g4GAHtojuFA0bNsTBgwcd3YxKZebMmY5uwm3PONxUNJD4+fmp3fWVoXJTeUZL3aFKG28DFJYfjQfwlbjS/PVX4b/t2xceLUU25+7ubnJkX40aNRw+aI6IqLyMA40two25/zsK94IOVla4ASxcAZVww0PANWXcdcguKSK6nRmHkIqGG1sGJVtguHEwS8KNRYl4377CfxluNGW8/HmOGyK6ndky3LByQyZsEm4yMoDjxwv/z3CjKePlz8oNEd3ObBlIGG7IhE26pQ4eBAwGoGZNgDtcTbFbioichS27kipbtxRHQzqYTSo3aWlAw4ZAkfMGke2xckNEzsKZu6UYbhxMCTfmznGjKHOlGTiw8HbzGiGkHVZuiMhZOHO4YbeUg1lbuSl1BeRhyZpj5YaInIVWh4JXhm4phhsHs3bMTbFEbDAAIhq0jMxh5YaInIVWh4KzckPq2SHLPebmr7+AgADgwQc1aB0VpSx/Nzc3VK1a1cGtISIqPx4tRZpISkrCvpvnpynt+ijKiuLq6mpyhlwAwOHDQGoqkJmpVTPJiPJZhIaGqhfPJCK6HfEMxaSJ77//Hvn5+WjTpg0aNmxY4nTKSufr6wudTmf6x8OHC/9t3VqbRpIJpVpTq1YtB7eEiKhinPkMxRyB6kDffvstAODRRx8tdTplBTSbhg8dKvyX4cYu7r33XowaNQr/+te/HN0UIqIKceajpRhuHOTSpUv4/fffAQAPP/xwqdOGhIQAKLxQo4n8fODo0cL/M9zYhY+PD5bwqutE5ASqV68OnU4Hf39/uLu7V2he1apVg16vh5eXF7y9vW3UwvJjuHGQNWvWQETQvXt3hIeHlzptly5dsGDBAnTq1Mn0D2fPAtnZgLc3UK+ehq0lIiJnExwcjFWrVqFatWoVnldgYCDWrFkDHx+fSjEekeHGQf744w8AwJAhQ8qcVqfT4fnnny/+B2W8TcuWgIuL7RpHRER3hEceecRm83qwEh21y3DjIDk5OQAK0265BQYCAwYAbdvaqFVERES3P4YbB8m/eakE14qcVfjeewtvREREpHJ8x9gdKi8vD0DhyeCIiIjIdhhuHMQmlRsiIiIqhuHGQZTKDcMNERGRbTHcOIhSuWG3FBERkW0x3DgIKzdERETaYLhxEFZuiIiItMFw4yCs3BAREWmD4cZBWLkhIiLSBsONg7ByQ0REpA2GGwdh5YaIiEgbDDcOwsoNERGRNhhuHISVGyIiIm0w3DgIKzdERETaYLhxEFZuiIiItMFw4yC8cCYREZE2GG4cQERYuSEiItIIw40DFBQUqP9n5YaIiMi2GG4cQBlMDLByQ0REZGsMNw6gdEkBrNwQERHZGsONA7ByQ0REpB2GGwcwrty4uLg4sCVERETOh+HGAZTKjYuLC3Q6nYNbQ0RE5FwYbhyAh4ETERFph+HGAXjpBSIiIu0w3DgAKzdERETaYbhxAFZuiIiItMNw4wCs3BAREWmH4cYBWLkhIiLSDsONA7ByQ0REpB2GGwdQwg0rN0RERLbHcOMASrcUKzdERES2x3DjAKzcEBERaYfhxgFYuSEiItIOw40DsHJDRESkHYYbB2DlhoiISDsMNw7Ayg0REZF2GG4cgJUbIiIi7TDcOAArN0RERNphuHEAXn6BiIhIO+UON//88w82b96MrKwsAICI2KxRzo6XXyAiItKO1eHm2rVr6Nu3Lxo2bIiBAwciPj4eAPDMM8/glVdesXkDnRErN0RERNqxOty8/PLLcHV1RUxMDKpUqaI+/vDDD2PTpk02bZyzYuWGiIhIO1aXDrZs2YLNmzejVq1aJo83aNAA0dHRNmuYM2PlhoiISDtWV24yMjJMKjaKpKQkeHh4lLsh06dPh06nw/jx40udbseOHWjXrh08PT1Rt25dLFq0qNyv6Sis3BAREWnH6nDTo0cPrFixQr2v0+lgMBgwa9Ys3H333eVqxL59+7BkyRK0bNmy1OkuXLiAgQMH4q677sKhQ4fw+uuv46WXXsLatWvL9bqOwkPBiYiItGP13nXWrFno1asX9u/fj9zcXEyaNAknTpzA9evXsXv3bqsbkJ6ejhEjRuDzzz/He++9V+q0ixYtQnh4OObNmwcAaNKkCfbv34/Zs2dj+PDhVr+2o/AkfkRERNqxunLTtGlTHD16FB07dkS/fv2QkZGBYcOG4dChQ6hXr57VDRgzZgzuu+8+9O3bt8xp9+zZg/79+5s8ds8992D//v1qYCgqJycHqampJjdHY+WGiIhIO1btXfPy8tC/f38sXrwY06ZNq/CLr169GgcPHsS+ffssmj4hIQE1atQweaxGjRrIz89HUlISQkNDiz1n+vTpNmmrLbFyQ0REpB2rKjdubm44fvw4dDpdhV84NjYW48aNw8qVK+Hp6Wnx84q+tnLywJLaNHnyZKSkpKi32NjY8jfaRli5ISIi0o7V3VJPPPEEli5dWuEXPnDgABITE9GuXTu4urrC1dUVO3bswPz58+Hq6oqCgoJizwkJCUFCQoLJY4mJiXB1dUXVqlXNvo6Hhwf8/PxMbo7Gyg0REZF2rC4d5Obm4osvvsDWrVvRvn17eHt7m/x97ty5Fs2nT58+OHbsmMljI0eOROPGjfHaa6/BxcWl2HO6dOmCH3/80eSxLVu2oH379rdVUGDlhoiISDtW712PHz+Otm3bAgDOnDlj8jdruqt8fX3RvHlzk8e8vb1RtWpV9fHJkycjLi5OPfR89OjR+PTTTzFhwgSMGjUKe/bswdKlS/Htt99a+zYcipUbIiIi7VgdbrZv365FO8yKj49HTEyMej8yMhI///wzXn75ZXz22WcICwvD/Pnzb6vDwAFWboiIiLRUqfauUVFRJveXLVtWbJqePXvi4MGD9mmQRli5ISIi0o7V4ebuu+8utftp27ZtFWrQnYCVGyIiIu1YvXdt3bq1yf28vDwcPnwYx48fx5NPPmmrdjk1Vm6IiIi0Y3W4+eijj8w+PnXqVKSnp1e4QXcCVm6IiIi0Y/V5bkryf//3f/jyyy9tNTunplRuGG6IiIhsz2bhZs+ePVadafhOplRu2C1FRERke1aXDoYNG2ZyX0QQHx+P/fv346233rJZw5wZu6WIiIi0Y/Xe1d/f3+S+Xq9Ho0aN8M477xS7YjeZxwHFRERE2rE63Hz11VdatOOOwsoNERGRdmw25oYsx8oNERGRdiwqHQQGBlp83ajr169XqEF3AlZuiIiItGPR3nXevHkaN+POwsoNERGRdiwKNzzzsG2xckNERKQdi/auqamp8PPzU/9fGmU6Kk5EoNPpWLkhIiLSkMVjbuLj4xEcHIyAgACz42+UHXdBQYHNG+kMduzYgeHDh+PTTz9l5YaIiEhDFu1dt23bhqCgIADA9u3bNW2Qs9qxYweuXbuGTZs2sXJDRESkIYvCTc+ePc3+nyynVGvS0tJYuSEiItJQufeumZmZiImJQW5ursnjLVu2rHCjnJESaNLT01m5ISIi0pDV4ebq1asYOXIkfvnlF7N/55gb81i5ISIisg+rz1A8fvx43LhxA3v37oWXlxc2bdqE5cuXo0GDBvjf//6nRRudgnG4YeWGiIhIO1aXDrZt24YffvgBHTp0gF6vR506ddCvXz/4+flh+vTpuO+++7Ro521PqWglJyerj7FyQ0REZHtWV24yMjIQHBwMAAgKCsLVq1cBAC1atMDBgwdt2zonolRubty4oT7GcENERGR7VoebRo0a4fTp0wCA1q1bY/HixYiLi8OiRYsQGhpq8wY6CyXcZGRkqI+xW4qIiMj2rC4djB8/HvHx8QCAKVOm4J577sE333wDd3d3LFu2zNbtcxpKuDHGyg0REZHtWX35hREjRqiPt2nTBhcvXsSpU6cQHh6OatWqadNKJ2DuKDKGGyIiItuzqFsqMDAQiYmJAIDevXubDIqtUqUK2rZty2BThqKVG71eD73e6l5BIiIiKoNFe1cfHx9cu3YNABAVFaUeykyWKxpuON6GiIhIGxb1i/Tt2xd33303mjRpAgAYOnQo3N3dzU67bds227XOiRQNN+ySIiIi0oZFe9iVK1di+fLlOHfuHHbs2IFmzZqhSpUqWrfNqRQdc8PKDRERkTYsCjdeXl4YPXo0AGD//v348MMPERAQoGW7nA4rN0RERPZh9R52+/btWrTD6XHMDRERkX3wcB07YeWGiIjIPhhu7IRjboiIiOyD4cZOWLkhIiKyD4YbO+GYGyIiIvsoV/kgOTkZS5cuxd9//w2dTocmTZrg6aefhr+/v63b5zRYuSEiIrIPqys3+/fvR7169fDRRx/h+vXrSEpKwkcffYR69erh4MGDWrTRKXDMDRERkX1YXT54+eWX8cADD+Dzzz9Xqw/5+fl45plnMH78eOzcudPmjXQGrNwQERHZh9V72P3795sEG6BwRz1p0iS0b9/epo1zJgw3RERE9mF1t5Sfnx9iYmKKPR4bGwtfX1+bNMoZcUAxERGRfVgdbh5++GE8/fTTWLNmDWJjY3Hp0iWsXr0azzzzDB599FEt2ugUio65YeWGiIhIG1bvYWfPng2dTocnnnhCrUa4ubnh+eefx4wZM2zeQGfByg0REZF9WB1u3N3d8fHHH2P69Ok4d+4cRAT169fnVcLLwDE3RERE9mF1t9S///1vpKWloUqVKmjRogVatmyJKlWqICMjA//+97+1aKNTYOWGiIjIPqwON8uXL0dWVlaxx7OysrBixQqbNMoZccwNERGRfVi8h01NTYWIQESQlpYGT09P9W8FBQX4+eefERwcrEkjnQErN0RERPZhcbgJCAiATqeDTqdDw4YNi/1dp9Nh2rRpNm2cM+GYGyIiIvuweA+7fft2iAh69+6NtWvXIigoSP2bu7s76tSpg7CwME0a6QyUcKPX62EwGFi5ISIi0ojF4aZnz54AgAsXLiA8PBw6nU6zRjkjZcxNQEAArl+/zsoNERGRRqweUFynTh0Gm3JQKjeBgYEAOOaGiIhIK1aHG7KewWCAiAC4FW5YuSEiItIGw40dGA8mDggIAMDKDRERkVYYbuzA+Bw3rNwQERFpy+pwk5WVhczMTPV+dHQ05s2bhy1btti0Yc7EuHLTunVrADB7OD0RERFVnE6UwSAW6t+/P4YNG4bRo0cjOTkZjRs3hpubG5KSkjB37lw8//zzWrXVJlJTU+Hv74+UlBT4+fnZ5TVv3LihHjqfk5ODuLg4REREcGA2ERGRhazZf1tduTl48CDuuusuAMD333+PGjVqIDo6GitWrMD8+fPL12InZ1y5cXV1RWRkJIMNERGRRqwON5mZmfD19QUAbNmyBcOGDYNer0fnzp0RHR1t8wY6A+MT+On1HOZERESkJav3tPXr18eGDRsQGxuLzZs3o3///gCAxMREu3Xz3G6UAcUcRExERKQ9q8PN22+/jYkTJyIiIgIdO3ZEly5dABRWcdq0aWPzBjoDpXLj4uLi4JYQERE5P6tLCQ8++CC6d++O+Ph4tGrVSn28T58+GDp0qE0b5yyUcMPKDRERkfbKtbcNCQlBSEgIYmNjodPpUKtWLXTs2NHWbXMaDDdERET2Y3W3VH5+Pt566y34+/sjIiICderUgb+/P958803k5eVp0cbbHsfcEBER2Y/V4Wbs2LFYsmQJZs6ciUOHDuHQoUOYOXMmli5dihdffNGqeS1cuBAtW7aEn58f/Pz80KVLF/zyyy8lTh8VFQWdTlfsdurUKWvfhl1xzA0REZH9WF1K+Pbbb7F69WoMGDBAfaxly5YIDw/HI488gkWLFlk8r1q1amHGjBmoX78+AGD58uUYPHgwDh06hGbNmpX4vNOnT5scmVW9enVr34ZdsVuKiIjIfqze23p6eiIiIqLY4xEREXB3d7dqXvfff7/J/ffffx8LFy7E3r17Sw03wcHB6gUoy5KTk4OcnBz1fmpqqlVttAWGGyIiIvuxultqzJgxePfdd00CQ05ODt5//32MHTu23A0pKCjA6tWrkZGRoR5eXpI2bdogNDQUffr0wfbt20uddvr06fD391dvtWvXLncby4tjboiIiOzH6r3toUOH8Ntvv6FWrVrqoeBHjhxBbm4u+vTpg2HDhqnTrlu3rsz5HTt2DF26dEF2djZ8fHywfv16NG3a1Oy0oaGhWLJkCdq1a4ecnBx8/fXX6NOnD6KiotCjRw+zz5k8eTImTJig3k9NTbV7wOGYGyIiIvuxOtwEBARg+PDhJo9VJCw0atQIhw8fRnJyMtauXYsnn3wSO3bsMBtwGjVqhEaNGqn3u3TpgtjYWMyePbvEcOPh4QEPD49yt88W2C1FRERkP1bvbb/66iubNsDd3V0dUNy+fXvs27cPH3/8MRYvXmzR8zt37oyVK1fatE22xnBDRERkP+W6imN+fj5+/fVXLF68GGlpaQCAy5cvIz09vcINEhGT8TxlOXToEEJDQyv8ulrimBsiIiL7sXpvGx0djXvvvRcxMTHIyclBv3794Ovri5kzZyI7O9uqQ8Fff/11DBgwALVr10ZaWhpWr16NqKgobNq0CUDheJm4uDisWLECADBv3jxERESgWbNmyM3NxcqVK7F27VqsXbvW2rdhVxxzQ0REZD9Wh5tx48ahffv2OHLkCKpWrao+PnToUDzzzDNWzevKlSt4/PHHER8fD39/f7Rs2RKbNm1Cv379AADx8fGIiYlRp8/NzcXEiRMRFxcHLy8vNGvWDBs3bsTAgQOtfRt2xW4pIiIi+7F6b7tr1y7s3r272Dlt6tSpg7i4OKvmtXTp0lL/vmzZMpP7kyZNwqRJk6x6jcqA4YaIiMh+rB5zYzAY1DEkxi5dugRfX1+bNMrZcMwNERGR/Vgdbvr164d58+ap93U6HdLT0zFlypRK3z3kKBxzQ0REZD9WlxI++ugj3H333WjatCmys7Px2GOP4ezZs6hWrRq+/fZbLdp422O3FBERkf1YvbcNCwvD4cOHsXr1ahw4cAAGgwFPP/00RowYAS8vLy3aeNtjuCEiIrIfq/e2O3fuRNeuXTFy5EiMHDlSfTw/Px87d+4s8UzBdzKOuSEiIrIfq8fc3H333bh+/Xqxx1NSUnD33XfbpFHOhpUbIiIi+7E63IgIdDpdscevXbsGb29vmzTK2XBAMRERkf1YXEpQrvat0+nw1FNPmVyMsqCgAEePHkXXrl1t30InwMoNERGR/Vi8t/X39wdQWLnx9fU1GTzs7u6Ozp07Y9SoUbZvoRPgmBsiIiL7sXhvq1wNPCIiAhMnTmQXlBVYuSEiIrIfq8fcTJo0yWTMTXR0NObNm4ctW7bYtGHOhGNuiIiI7MfqcDN48GD1Kt3Jycno2LEj5syZg8GDB2PhwoU2b6AzYOWGiIjIfqwONwcPHsRdd90FAPj+++8REhKC6OhorFixAvPnz7d5A50Bx9wQERHZj9XhJjMzU71A5pYtWzBs2DDo9Xp07twZ0dHRNm+gM2DlhoiIyH6sDjf169fHhg0bEBsbi82bN6N///4AgMTERPj5+dm8gc6AY26IiIjsx+pw8/bbb2PixImIiIhAp06d0KVLFwCFVZw2bdrYvIHOgJUbIiIi+7F6b/vggw+ie/fuiI+PR6tWrdTH+/Tpg6FDh9q0cc6CY26IiIjsp1x725CQEISEhJg81rFjR5s0yBmxckNERGQ/VndLkfU45oaIiMh+GG7sgJUbIiIi+2G4sQOGGyIiIvthuLEDDigmIiKyn3LtbePi4rB7924kJibCYDCY/O2ll16yScOcCcfcEBER2Y/V4earr77C6NGj4e7ujqpVq5pcRFOn0zHcmMFuKSIiIvuxem/79ttv4+2338bkyZOh17NXyxIMN0RERPZTrmtLPfLIIww2VuCYGyIiIvuxOqE8/fTT+O6777Roi9PimBsiIiL7sbqUMH36dAwaNAibNm1CixYt4ObmZvL3uXPn2qxxzoLdUkRERPZj9d72gw8+wObNm9GoUSMAKDagmIpjuCEiIrIfq/e2c+fOxZdffomnnnpKg+Y4J465ISIish+rx9x4eHigW7duWrTFaXHMDRERkf1YHW7GjRuHTz75RIu2OC12SxEREdmP1Xvbv/76C9u2bcNPP/2EZs2aFRtQvG7dOps1zlkw3BAREdmP1XvbgIAADBs2TIu2OC2OuSEiIrKfcl1+gazDyg0REZH98DTDdsABxURERPZjdSkhMjKy1PPZnD9/vkINckas3BAREdmP1Xvb8ePHm9zPy8vDoUOHsGnTJrz66qu2apdT4ZgbIiIi+7F6bztu3Dizj3/22WfYv39/hRvkjFi5ISIish+bjbkZMGAA1q5da6vZORWOuSEiIrIfm4Wb77//HkFBQbaanVNh5YaIiMh+rN7btmnTxmRAsYggISEBV69exYIFC2zaOGfBMTdERET2Y/XedsiQISb39Xo9qlevjl69eqFx48a2apdTYeWGiIjIfqze206ZMkWLdjg1jrkhIiKyH57Ezw5YuSEiIrIfi/e2er2+1JP3AYBOp1N35FTIYDBARAAw3BAREdmDxXvb9evXl/i3P/74A5988om6E6dblMHEAMMNERGRPVi8tx08eHCxx06dOoXJkyfjxx9/xIgRI/Duu+/atHHOwLiSxTE3RERE2ivXmJvLly9j1KhRaNmyJfLz83H48GEsX74c4eHhtm7fbc843LByQ0REpD2rwk1KSgpee+011K9fHydOnMBvv/2GH3/8Ec2bN9eqfbc9dksRERHZl8V725kzZ+LDDz9ESEgIvv32W7PdVFQcu6WIiIjsSycWjgLW6/Xw8vJC3759S91Jr1u3zmaN00Jqair8/f2RkpICPz8/zV8vISEBoaGh0Ol0MBgMmr8eERGRM7Jm/21x5eaJJ54o81BwKo7nuCEiIrIvi/e4y5Yt07AZzovXlSIiIrIvnqFYY6zcEBER2RfDjcZ4XSkiIiL7YrjRGCs3RERE9sVwozGGGyIiIvtiuNEYBxQTERHZF8ONxjjmhoiIyL4cGm4WLlyIli1bws/PD35+fujSpQt++eWXUp+zY8cOtGvXDp6enqhbty4WLVpkp9aWD7uliIiI7Muh4aZWrVqYMWMG9u/fj/3796N3794YPHgwTpw4YXb6CxcuYODAgbjrrrtw6NAhvP7663jppZewdu1aO7fccgw3RERE9uXQPe79999vcv/999/HwoULsXfvXjRr1qzY9IsWLUJ4eDjmzZsHAGjSpAn279+P2bNnY/jw4fZostU45oaIiMi+Ks2Ym4KCAqxevRoZGRno0qWL2Wn27NmD/v37mzx2zz33YP/+/cjLyzP7nJycHKSmpprc7ImVGyIiIvtyeLg5duwYfHx84OHhgdGjR2P9+vVo2rSp2WkTEhJQo0YNk8dq1KiB/Px8JCUlmX3O9OnT4e/vr95q165t8/dQGg4oJiIisi+Hh5tGjRrh8OHD2Lt3L55//nk8+eSTOHnyZInTF714p3JR85Iu6jl58mSkpKSot9jYWNs13gKs3BAREdmXw/e47u7uqF+/PgCgffv22LdvHz7++GMsXry42LQhISFISEgweSwxMRGurq6oWrWq2fl7eHjAw8PD9g23EMfcEBER2ZfDKzdFiQhycnLM/q1Lly7YunWryWNbtmxB+/bt4ebmZo/mWY2VGyIiIvtyaLh5/fXX8fvvv+PixYs4duwY3njjDURFRWHEiBEACruUnnjiCXX60aNHIzo6GhMmTMDff/+NL7/8EkuXLsXEiRMd9RbKxDE3RERE9uXQcsKVK1fw+OOPIz4+Hv7+/mjZsiU2bdqEfv36AQDi4+MRExOjTh8ZGYmff/4ZL7/8Mj777DOEhYVh/vz5lfYwcICVGyIiIntz6B536dKlpf592bJlxR7r2bMnDh48qFGLbI9jboiIiOyr0o25cTbK+XfYLUVERGQfDDcaS09PBwD4+vo6uCVERER3BoYbjSlnRPbz83NwS4iIiO4MDDcaS0lJAcBwQ0REZC8MNxpTKjf+/v4ObgkREdGdgeFGY6zcEBER2RfDjcY45oaIiMi+GG40xm4pIiIi+2K40Ri7pYiIiOyL4UZjrNwQERHZF8ONxjjmhoiIyL4YbjRkMBiQlpYGgOGGiIjIXhhuNJSeng4RAcBuKSIiInthuNGQ0iXl5uYGDw8PB7eGiIjozsBwoyHlSCl/f3/odDoHt4aIiOjOwHCjIQ4mJiIisj+GGw3xHDdERET2x3CjIZ7jhoiIyP4YbjTEbikiIiL7Y7jRELuliIiI7I/hRkPsliIiIrI/hhsNsVuKiIjI/hhuNGR8nhsiIiKyD4YbDbFyQ0REZH8MNxrigGIiIiL7Y7jREAcUExER2R/DjYbYLUVERGR/DDcaYrcUERGR/THcaIjdUkRERPbHcKORgoICZGRkAGDlhoiIyJ4YbjSiVG0AhhsiIiJ7YrjRiBJuPD094e7u7uDWEBER3TkYbjTCwcRERESOwXCjEQ4mJiIicgyGG42wckNEROQYDDca4UUziYiIHIPhRiMMN0RERI7BcKMRJdwEBAQ4tiFERER3GIYbjSQnJwNg5YaIiMjeGG40wm4pIiIix2C40QjDDRERkWMw3GiEY26IiIgcg+FGIxxzQ0RE5BgMNxphtxQREZFjMNxohOGGiIjIMRhuNMIxN0RERI7BcKOBgoICpKWlAWDlhoiIyN4YbjSgXBEcYLghIiKyN4YbDShdUp6ennB3d3dwa4iIiO4sDDca4HgbIiIix2G40QDPcUNEROQ4DDca4GHgREREjsNwowGGGyIiIsdhuNGA0i3FMTdERET2x3CjAVZuiIiIHIfhRgMMN0RERI7DcKMBhhsiIiLHYbjRAMfcEBEROQ7DjQZYuSEiInIchhsNMNwQERE5DsONBhhuiIiIHMeh4Wb69Ono0KEDfH19ERwcjCFDhuD06dOlPicqKgo6na7Y7dSpU3Zqddl4+QUiIiLHcWi42bFjB8aMGYO9e/di69atyM/PR//+/ZGRkVHmc0+fPo34+Hj11qBBAzu02DK8cCYREZHjuDryxTdt2mRy/6uvvkJwcDAOHDiAHj16lPrc4OBgi8JDTk4OcnJy1PupqanlaqulcnNzkZWVBYCVGyIiIkeoVGNulIpHUFBQmdO2adMGoaGh6NOnD7Zv317idNOnT4e/v796q127ts3aa47yHgDAz89P09ciIiKi4nQiIo5uBACICAYPHowbN27g999/L3G606dPY+fOnWjXrh1ycnLw9ddfY9GiRYiKijJb7TFXualduzZSUlI0CR///PMPGjRoAG9vb6Snp9t8/kRERHei1NRU+Pv7W7T/dmi3lLGxY8fi6NGj2LVrV6nTNWrUCI0aNVLvd+nSBbGxsZg9e7bZcOPh4QEPDw+bt7ckSUlJACyrPhEREZHtVYpuqRdffBH/+9//sH37dtSqVcvq53fu3Blnz57VoGXWO3PmDACgXr16Dm4JERHRncmhlRsRwYsvvoj169cjKioKkZGR5ZrPoUOHEBoaauPWlY9yKLtxdYmIiIjsx6HhZsyYMVi1ahV++OEH+Pr6IiEhAUDhUUZeXl4AgMmTJyMuLg4rVqwAAMybNw8RERFo1qwZcnNzsXLlSqxduxZr16512PswpoSbxo0bO7glREREdyaHhpuFCxcCAHr16mXy+FdffYWnnnoKABAfH4+YmBj1b7m5uZg4cSLi4uLg5eWFZs2aYePGjRg4cKC9ml0qVm6IiIgcq9IcLWUv1oy2tlZBQQG8vb2Rk5ODc+fOoW7dujadPxER0Z3Kmv13pRhQ7CxiYmKQk5MDDw8P1KlTx9HNISIiuiMx3NiQ0iVVv359uLi4OLg1REREdyaGGxvieBsiIiLHY7ixIYYbIiIix2O4sSGGGyIiIsdjuLEhhhsiIiLHY7ixkbS0NMTFxQFguCEiInKkSnPhzNtdfHw8atSoAYPBgMDAQEc3h4iI6I7FcGMjDRs2REJCAjIyMhzdFCIiojsau6VszNvb29FNICIiuqMx3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORVXRzfA3kQEAJCamurglhAREZGllP22sh8vzR0XbtLS0gAAtWvXdnBLiIiIyFppaWnw9/cvdRqdWBKBnIjBYMDly5fh6+sLnU5n03mnpqaidu3aiI2NhZ+fn03nTaXjsnccLnvH4bJ3HC57+xMRpKWlISwsDHp96aNq7rjKjV6vR61atTR9DT8/P67sDsJl7zhc9o7DZe84XPb2VVbFRsEBxURERORUGG6IiIjIqTDc2JCHhwemTJkCDw8PRzfljsNl7zhc9o7DZe84XPaV2x03oJiIiIicGys3RERE5FQYboiIiMipMNwQERGRU2G4ISIiIqfCcGMjCxYsQGRkJDw9PdGuXTv8/vvvjm6S05k6dSp0Op3JLSQkRP27iGDq1KkICwuDl5cXevXqhRMnTjiwxbevnTt34v7770dYWBh0Oh02bNhg8ndLlnVOTg5efPFFVKtWDd7e3njggQdw6dIlO76L21dZy/+pp54q9l3o3LmzyTRc/tabPn06OnToAF9fXwQHB2PIkCE4ffq0yTRc928PDDc2sGbNGowfPx5vvPEGDh06hLvuugsDBgxATEyMo5vmdJo1a4b4+Hj1duzYMfVvM2fOxNy5c/Hpp59i3759CAkJQb9+/dTriZHlMjIy0KpVK3z66adm/27Jsh4/fjzWr1+P1atXY9euXUhPT8egQYNQUFBgr7dx2ypr+QPAvffea/Jd+Pnnn03+zuVvvR07dmDMmDHYu3cvtm7divz8fPTv3x8ZGRnqNFz3bxNCFdaxY0cZPXq0yWONGzeW//znPw5qkXOaMmWKtGrVyuzfDAaDhISEyIwZM9THsrOzxd/fXxYtWmSnFjonALJ+/Xr1viXLOjk5Wdzc3GT16tXqNHFxcaLX62XTpk12a7szKLr8RUSefPJJGTx4cInP4fK3jcTERAEgO3bsEBGu+7cTVm4qKDc3FwcOHED//v1NHu/fvz/++OMPB7XKeZ09exZhYWGIjIzEI488gvPnzwMALly4gISEBJPPwcPDAz179uTnYGOWLOsDBw4gLy/PZJqwsDA0b96cn4eNREVFITg4GA0bNsSoUaOQmJio/o3L3zZSUlIAAEFBQQC47t9OGG4qKCkpCQUFBahRo4bJ4zVq1EBCQoKDWuWcOnXqhBUrVmDz5s34/PPPkZCQgK5du+LatWvqsubnoD1LlnVCQgLc3d0RGBhY4jRUfgMGDMA333yDbdu2Yc6cOdi3bx969+6NnJwcAFz+tiAimDBhArp3747mzZsD4Lp/O7njrgquFZ1OZ3JfRIo9RhUzYMAA9f8tWrRAly5dUK9ePSxfvlwdTMnPwX7Ks6z5edjGww8/rP6/efPmaN++PerUqYONGzdi2LBhJT6Py99yY8eOxdGjR7Fr165if+O6X/mxclNB1apVg4uLS7FEnpiYWCzdk215e3ujRYsWOHv2rHrUFD8H7VmyrENCQpCbm4sbN26UOA3ZTmhoKOrUqYOzZ88C4PKvqBdffBH/+9//sH37dtSqVUt9nOv+7YPhpoLc3d3Rrl07bN261eTxrVu3omvXrg5q1Z0hJycHf//9N0JDQxEZGYmQkBCTzyE3Nxc7duzg52Bjlizrdu3awc3NzWSa+Ph4HD9+nJ+HBq5du4bY2FiEhoYC4PIvLxHB2LFjsW7dOmzbtg2RkZEmf+e6fxtx2FBmJ7J69Wpxc3OTpUuXysmTJ2X8+PHi7e0tFy9edHTTnMorr7wiUVFRcv78edm7d68MGjRIfH191eU8Y8YM8ff3l3Xr1smxY8fk0UcfldDQUElNTXVwy28/aWlpcujQITl06JAAkLlz58qhQ4ckOjpaRCxb1qNHj5ZatWrJr7/+KgcPHpTevXtLq1atJD8/31Fv67ZR2vJPS0uTV155Rf744w+5cOGCbN++Xbp06SI1a9bk8q+g559/Xvz9/SUqKkri4+PVW2ZmpjoN1/3bA8ONjXz22WdSp04dcXd3l7Zt26qHDpLtPPzwwxIaGipubm4SFhYmw4YNkxMnTqh/NxgMMmXKFAkJCREPDw/p0aOHHDt2zIEtvn1t375dABS7PfnkkyJi2bLOysqSsWPHSlBQkHh5ecmgQYMkJibGAe/m9lPa8s/MzJT+/ftL9erVxc3NTcLDw+XJJ58stmy5/K1nbpkDkK+++kqdhuv+7UEnImLvahERERGRVjjmhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhohuSyKCZ599FkFBQdDpdDh8+HCZz7l48aLJtFFRUdDpdEhOTta0rURkXww3RFSmp556CjqdDjNmzDB5fMOGDdDpdA5p06ZNm7Bs2TL89NNPiI+PR/Pmzct8Tu3atS2elohuXww3RGQRT09PfPjhh7hx44ajmwIAOHfuHEJDQ9G1a1eEhITA1dW1zOe4uLhYPK2lcnNzbTYvIrINhhsiskjfvn0REhKC6dOnlzjN1KlT0bp1a5PH5s2bh4iICPX+U089hSFDhuCDDz5AjRo1EBAQgGnTpiE/Px+vvvoqgoKCUKtWLXz55Zclvs5TTz2FF198ETExMdDpdOr8N23ahO7duyMgIABVq1bFoEGDcO7cOfV5RbulKtL+6dOnIywsDA0bNgQAxMXF4eGHH0ZgYCCqVq2KwYMH4+LFi+rzoqKi0LFjR3h7eyMgIADdunVDdHR0ie+RiMqP4YaILOLi4oIPPvgAn3zyCS5dulSheW3btg2XL1/Gzp07MXfuXEydOhWDBg1CYGAg/vzzT4wePRqjR49GbGys2ed//PHHeOedd1CrVi3Ex8dj3759AICMjAxMmDAB+/btw2+//Qa9Xo+hQ4fCYDBUqL1F/fbbb/j777+xdetW/PTTT8jMzMTdd98NHx8f7Ny5E7t27YKPjw/uvfde5ObmIj8/H0OGDEHPnj1x9OhR7NmzB88++6zDuvSInJ3tarNE5PSGDh2K1q1bY8qUKVi6dGm55xMUFIT58+dDr9ejUaNGmDlzJjIzM/H6668DACZPnowZM2Zg9+7deOSRR4o939/fH76+vmo3k2L48OEm0y1duhTBwcE4efKkTcfZeHt744svvoC7uzsA4Msvv4Rer8cXX3yhBpavvvoKAQEBiIqKQvv27ZGSkoJBgwahXr16AIAmTZrYrD1EZIqVGyKyyocffojly5fj5MmT5Z5Hs2bNoNff2vzUqFEDLVq0UO+7uLigatWqSExMtGq+586dw2OPPYa6devCz88PkZGRAICYmJhyt9WcFi1aqMEGAA4cOIB//vkHvr6+8PHxgY+PD4KCgpCdnY1z584hKCgITz31FO655x7cf//9+PjjjxEfH2/TNhHRLQw3RGSVHj164J577lGrLMb0ej1ExOSxvLy8YtO5ubmZ3NfpdGYfs7Y76f7778e1a9fw+eef488//8Sff/4JwPJBv5a239vb2+S+wWBAu3btcPjwYZPbmTNn8NhjjwEorOTs2bMHXbt2xZo1a9CwYUPs3bvXqvdHRJZhtxQRWW3GjBlo3bq1OphWUb16dSQkJEBE1O4ZS84/YwvXrl3D33//jcWLF+Ouu+4CAOzatcuqeZS3/W3btsWaNWsQHBwMPz+/Eqdr06YN2rRpg8mTJ6NLly5YtWoVOnfubFUbiahsrNwQkdVatGiBESNG4JNPPjF5vFevXrh69SpmzpyJc+fO4bPPPsMvv/xilzYpRyktWbIE//zzD7Zt24YJEyZYNY/ytn/EiBGoVq0aBg8ejN9//x0XLlzAjh07MG7cOFy6dAkXLlzA5MmTsWfPHkRHR2PLli04c+YMx90QaYThhojK5d133y3WhdOkSRMsWLAAn332GVq1aoW//voLEydOtEt79Ho9Vq9ejQMHDqB58+Z4+eWXMWvWLKvmUd72V6lSBTt37kR4eDiGDRuGJk2a4N///jeysrLg5+eHKlWq4NSpUxg+fDgaNmyIZ599FmPHjsVzzz1X3rdLRKXQSdGtExEREdFtjJUbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqfw/2/t0DWAB0OYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "value_function_array = np.random.uniform(0, 0.1, NUM_STATES)\n",
    "states_reward = np.zeros(NUM_STATES)\n",
    "transition_matrix = np.zeros(shape=(NUM_STATES, NUM_ACTIONS, NUM_STATES)) + 1 / NUM_STATES\n",
    "\n",
    "\n",
    "counter_state_action = np.zeros(shape=(NUM_STATES, NUM_ACTIONS))\n",
    "counter_state_action_next_state = np.zeros(shape=(NUM_STATES, NUM_ACTIONS, NUM_STATES))\n",
    "counter_state_for_reward = np.zeros(NUM_STATES)\n",
    "sum_of_rewards_per_state = np.zeros(NUM_STATES)\n",
    "\n",
    "# This is the criterion to end the simulation.\n",
    "# You should change it to terminate when the previous\n",
    "# 'NO_LEARNING_THRESHOLD' consecutive value function computations all\n",
    "# converged within one value function iteration. Intuitively, it seems\n",
    "# like there will be little learning after this, so end the simulation\n",
    "# here, and say the overall algorithm has converged.\n",
    "consecutive_no_learning_trials = 0\n",
    "\n",
    "while consecutive_no_learning_trials < NO_LEARNING_THRESHOLD:\n",
    "\n",
    "    # Write code to choose action (0 or 1).\n",
    "    # This action choice algorithm is just for illustration. It may\n",
    "    # convince you that reinforcement learning is nice for control\n",
    "    # problems!Replace it with your code to choose an action that is\n",
    "    # optimal according to the current value function, and the current MDP\n",
    "    # model.\n",
    "    sum_for_action_0 = np.dot(transition_matrix[state][0], value_function_array)\n",
    "    sum_for_action_1 = np.dot(transition_matrix[state][1], value_function_array)\n",
    "    action = 0 if sum_for_action_0 > sum_for_action_1 else 1\n",
    "\n",
    "    # Get the next state by simulating the dynamics\n",
    "    state_tuple = cart_pole.simulate(action, state_tuple)\n",
    "    # x, x_dot, theta, theta_dot = state_tuple\n",
    "\n",
    "    # Increment simulation time\n",
    "    time = time + 1\n",
    "\n",
    "    # Get the state number corresponding to new state vector\n",
    "    new_state = cart_pole.get_state(state_tuple)\n",
    "    # if display_started == 1:\n",
    "    #     cart_pole.show_cart(state_tuple, pause_time)\n",
    "\n",
    "    # reward function to use - do not change this!\n",
    "    if new_state == NUM_STATES - 1:\n",
    "        R = -1\n",
    "    else:\n",
    "        R = 0\n",
    "\n",
    "    # Perform model updates here.\n",
    "    # A transition from `state` to `new_state` has just been made using\n",
    "    # `action`. The reward observed in `new_state` (note) is `R`.\n",
    "    # Write code to update your statistics about the MDP i.e. the\n",
    "    # information you are storing on the transitions and on the rewards\n",
    "    # observed. Do not change the actual MDP parameters, except when the\n",
    "    # pole falls (the next if block)!\n",
    "    counter_state_action[state, action] += 1\n",
    "    counter_state_action_next_state[state, action, new_state] += 1\n",
    "    counter_state_for_reward[new_state] += 1\n",
    "    sum_of_rewards_per_state[new_state] += R\n",
    "    # raise NotImplementedError('Update T and R not implemented')\n",
    "    # record the number of times `state, action, new_state` occurs\n",
    "    # record the rewards for every `new_state`\n",
    "    # record the number of time `new_state` was reached\n",
    "\n",
    "    # Recompute MDP model whenever pole falls\n",
    "    # Compute the value function V for the new model\n",
    "    if new_state == NUM_STATES - 1:\n",
    "        # Update MDP model using the current accumulated statistics about the\n",
    "        # MDP - transitions and rewards.\n",
    "        # Make sure you account for the case when a state-action pair has never\n",
    "        # been tried before, or the state has never been visited before. In that\n",
    "        # case, you must not change that component (and thus keep it at the\n",
    "        # initialized uniform distribution).\n",
    "        for i in range(NUM_STATES):\n",
    "            for a in range(NUM_ACTIONS):\n",
    "                if counter_state_action[i][a] != 0:\n",
    "                    transition_matrix[i][a] = counter_state_action_next_state[i][a] / counter_state_action[i][a]\n",
    "            if counter_state_for_reward[i] != 0:\n",
    "                states_reward[i] = sum_of_rewards_per_state[i] / counter_state_for_reward[i]\n",
    "\n",
    "        # Perform value iteration using the new estimated model for the MDP.\n",
    "        # The convergence criterion should be based on `TOLERANCE` as described\n",
    "        # at the top of the file.\n",
    "        # If it converges within one iteration, you may want to update your\n",
    "        # variable that checks when the whole simulation must end.\n",
    "        next_iter_value_function_array = np.zeros(NUM_STATES)\n",
    "        number_of_iteration_till_converge = 0\n",
    "        while True:\n",
    "            for i in range(NUM_STATES):\n",
    "                sum_for_action_0 = np.dot(transition_matrix[i][0], value_function_array)\n",
    "                sum_for_action_1 = np.dot(transition_matrix[i][1], value_function_array)\n",
    "                next_iter_value_function_array[i] = states_reward[i] + GAMMA * (\n",
    "                    sum_for_action_0 if sum_for_action_0 > sum_for_action_1 else sum_for_action_1)\n",
    "            if np.linalg.norm(value_function_array - next_iter_value_function_array, ord=np.inf) < TOLERANCE:\n",
    "                if number_of_iteration_till_converge == 0:\n",
    "                    consecutive_no_learning_trials += 1\n",
    "                else:\n",
    "                    consecutive_no_learning_trials = 0\n",
    "                value_function_array = next_iter_value_function_array\n",
    "                break\n",
    "            else:\n",
    "                number_of_iteration_till_converge += 1\n",
    "                value_function_array = next_iter_value_function_array\n",
    "\n",
    "    # Do NOT change this code: Controls the simulation, and handles the case\n",
    "    # when the pole fell and the state must be reinitialized.\n",
    "    if new_state == NUM_STATES - 1:\n",
    "        num_failures += 1\n",
    "        if num_failures >= max_failures:\n",
    "            break\n",
    "        print('[INFO] Failure number {}'.format(num_failures))\n",
    "        time_steps_to_failure.append(time - time_at_start_of_current_trial)\n",
    "        # time_steps_to_failure[num_failures] = time - time_at_start_of_current_trial\n",
    "        time_at_start_of_current_trial = time\n",
    "\n",
    "        if time_steps_to_failure[num_failures - 1] > min_trial_length_to_start_display:\n",
    "            display_started = 1\n",
    "\n",
    "        # Reinitialize state\n",
    "        # x = 0.0\n",
    "        x = -1.1 + np.random.uniform() * 2.2\n",
    "        x_dot, theta, theta_dot = 0.0, 0.0, 0.0\n",
    "        state_tuple = (x, x_dot, theta, theta_dot)\n",
    "        state = cart_pole.get_state(state_tuple)\n",
    "    else:\n",
    "        state = new_state\n",
    "\n",
    "# plot the learning curve (time balanced vs. trial)\n",
    "log_tstf = np.log(np.array(time_steps_to_failure))\n",
    "plt.plot(np.arange(len(time_steps_to_failure)), log_tstf, 'k')\n",
    "window = 30\n",
    "w = np.array([1 / window for _ in range(window)])\n",
    "weights = lfilter(w, 1, log_tstf)\n",
    "x = np.arange(window // 2, len(log_tstf) - window // 2)\n",
    "plt.plot(x, weights[window:len(log_tstf)], 'r--')\n",
    "plt.xlabel('Num failures')\n",
    "plt.ylabel('Num steps to failure')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47592815",
   "metadata": {},
   "source": [
    "# Frozen Lake"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b0ceee5",
   "metadata": {},
   "source": [
    "## Tabular Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "029f4c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in d:\\conda\\envs\\pytorch\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: shimmy<1.0,>=0.1.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (0.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.11.0)\n",
      "Requirement already satisfied: tqdm in d:\\conda\\envs\\pytorch\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\conda\\envs\\pytorch\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: gymnasium[toy_text] in d:\\conda\\envs\\pytorch\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (1.22.3)\n",
      "Requirement already satisfied: shimmy<1.0,>=0.1.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (0.2.0)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (4.11.3)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from gymnasium[toy_text]) (0.0.1)\n",
      "Collecting pygame==2.1.3.dev8\n",
      "  Downloading pygame-2.1.3.dev8-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\conda\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[toy_text]) (3.11.0)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.3.dev8\n"
     ]
    }
   ],
   "source": [
    "! pip install gymnasium\n",
    "! pip install tqdm\n",
    "! pip install gymnasium[toy_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5405a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4000/4000 [00:01<00:00, 2482.16it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new game. try: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:25<03:53, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new game. try: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:35<05:23, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.4\n",
      "Final Q-Table Values\n",
      "[[2.36373283e-01 3.51932824e-02 2.88854757e-02 4.60522491e-02]\n",
      " [9.54735777e-04 1.65314640e-02 6.18991548e-04 2.31042878e-02]\n",
      " [2.20017282e-02 2.90299627e-03 6.24966025e-03 6.69509745e-02]\n",
      " [4.41477899e-03 3.49040863e-03 1.82017583e-02 2.09139328e-02]\n",
      " [2.11656415e-01 1.10866512e-04 2.39554450e-03 5.06900448e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.75958897e-04 1.38746649e-04 4.56228417e-03 3.36097408e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.17475361e-03 1.39068946e-02 1.11879779e-04 2.40474602e-01]\n",
      " [1.34057078e-03 2.55207813e-01 1.13432143e-02 2.94735932e-04]\n",
      " [5.39821502e-02 1.29709266e-03 1.07082431e-02 6.73636450e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.77635991e-03 2.40020648e-02 1.79457126e-01 0.00000000e+00]\n",
      " [7.65312880e-03 0.00000000e+00 7.63784530e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"ansi\")\n",
    "\n",
    "# Implement Q-Table learning algorithm\n",
    "# Initialize table with all zeros\n",
    "\n",
    "# Set learning parameters\n",
    "LEARNING_RATE = .8\n",
    "GAMMA = .95\n",
    "NUM_EPISODES = 4000\n",
    "\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "rewards_list = []\n",
    "for episode_number in tqdm(range(NUM_EPISODES)):\n",
    "    # Reset environment and get first new observation\n",
    "    state = env.reset()[0]\n",
    "    total_episode_reward = 0  # Total reward during current episode\n",
    "    terminated = False\n",
    "    t = 0\n",
    "    # The Q-Table learning algorithm\n",
    "    while t < 99:\n",
    "        t += 1\n",
    "        action = np.argmax(Q[state] + np.random.normal(0, 0.01, size=Q.shape[1]))\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        CAPITAL_GAMMA = reward + GAMMA * np.max(Q[next_state]) - Q[state][action]\n",
    "        Q[state][action] = Q[state][action] + LEARNING_RATE * CAPITAL_GAMMA\n",
    "        total_episode_reward += reward\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        state = next_state\n",
    "\n",
    "    rewards_list.append(total_episode_reward)\n",
    "\n",
    "\n",
    "# a Final round to show the actual results\n",
    "for try_count in tqdm(range(10)):\n",
    "    print(f\"new game. try: {try_count+1}\")\n",
    "    # Re Load environment with human render mode to save in runtime\n",
    "    env = gym.make('FrozenLake-v1', render_mode=\"human\")\n",
    "    state = env.reset()[0]\n",
    "    terminated, truncated = False, False\n",
    "    t = 0\n",
    "    while t < 99:\n",
    "        t += 1\n",
    "        action = np.argmax(Q[state])\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        # if next_state != state:\n",
    "        #     # print(env.render())\n",
    "        #     env.render()\n",
    "        state = next_state\n",
    "        if terminated or truncated:\n",
    "            env.close()\n",
    "            break\n",
    "    if state == env.observation_space.n - 1:\n",
    "        env.close()\n",
    "        break\n",
    "\n",
    "\n",
    "# Reports\n",
    "print(\"Score over time: \" + str(sum(rewards_list) / NUM_EPISODES))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(Q)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee94491",
   "metadata": {},
   "source": [
    "## Deep Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5909417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4000/4000 [00:30<00:00, 131.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new game. try: 1\n",
      "Score over time: 0.4835\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "# sleep for 1 second\n",
    "import time\n",
    "\n",
    "# Load environment\n",
    "env = gym.make('FrozenLake-v1', render_mode='ansi')\n",
    "\n",
    "\n",
    "def get_one_hot(x, l):\n",
    "    x = torch.LongTensor([[x]])\n",
    "    one_hot = torch.FloatTensor(1, l)  # initialize the one-hot tensor\n",
    "    return one_hot.zero_().scatter_(1, x, 1)\n",
    "\n",
    "\n",
    "num_classes = 4\n",
    "input_size = 16\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, num_classes, bias=False))\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Implement Q-Network learning algorithm\n",
    "\n",
    "# Set learning parameters\n",
    "GAMMA = .99\n",
    "epsilon = 0.4\n",
    "NUM_EPISODES = 4000\n",
    "NUM_STATES = 16\n",
    "# create lists to contain total rewards and steps per episode\n",
    "episodes_lengths_list = []\n",
    "total_rewards_list = []\n",
    "for i in tqdm(range(NUM_EPISODES)):\n",
    "    # Reset environment and get first new observation\n",
    "    state = env.reset()[0]\n",
    "    rAll = 0\n",
    "    terminated, truncated = False, False\n",
    "    t = 0\n",
    "    # The Q-Network\n",
    "    while t < 99:\n",
    "        t += 1\n",
    "\n",
    "        Q = model(get_one_hot(state, NUM_STATES))\n",
    "\n",
    "        action = torch.argmax(Q).item()\n",
    "        if np.random.rand(1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        Q_tag = model(get_one_hot(new_state, NUM_STATES))\n",
    "        Q_target = Variable(Q.data)\n",
    "        Q_target[0][action] = reward + torch.mul(GAMMA, torch.max(Q_tag).item())\n",
    "        Q = model(get_one_hot(state, NUM_STATES))\n",
    "\n",
    "        loss = criterion(Q_target, Q)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        if terminated or truncated:\n",
    "            # Reduce chance of random action as we train the model.\n",
    "            epsilon = 1. / ((i / 50) + 10)\n",
    "            break\n",
    "    episodes_lengths_list.append(t)\n",
    "    total_rewards_list.append(rAll)\n",
    "\n",
    "\n",
    "# A final round to see the network's results in action\n",
    "model.eval()\n",
    "for try_count in range(10):\n",
    "    print(f\"new game. try: {try_count+1}\")\n",
    "    # Load environment\n",
    "    env = gym.make('FrozenLake-v1', render_mode='human')\n",
    "    state = env.reset()[0]\n",
    "    terminated, truncated = False, False\n",
    "    t = 0\n",
    "    while t < 99:\n",
    "        t += 1\n",
    "        Q = model(get_one_hot(state, NUM_STATES))\n",
    "        action = torch.argmax(Q).item()\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "        # if new_state != state:\n",
    "        #     print(env.render())\n",
    "        state = new_state\n",
    "        if terminated or truncated:\n",
    "            env.close()\n",
    "            break\n",
    "    if state == env.observation_space.n - 1:\n",
    "        break\n",
    "\n",
    "\n",
    "# Reports\n",
    "print(\"Score over time: \" + str(sum(total_rewards_list) / NUM_EPISODES))\n",
    "time.sleep(5)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7eedbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "322a509557a274cb16a0e1e68450414eb651dbdd02be71d467608ec080fac03e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
